<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>无痛的机器学习 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/hsmyy</link><description>专栏主营业务：让更多人能看的懂的机器学习科普+进阶文章。欢迎各位大神投稿或协助审阅。</description><lastBuildDate>Wed, 30 Nov 2016 21:15:59 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>FCN(6)——从CRF到RNN</title><link>https://zhuanlan.zhihu.com/p/22795755</link><description>前面我们花了大量的篇章介绍了CRF和DenseCRF的内容，下面我们把FCN和CRF串起来。&lt;h2&gt;CRFasRNN&lt;/h2&gt;&lt;p&gt;前面我们在denseCRF中留了一个小尾巴，那就是unary function。为了让FCN结合起来，这里我们做两个设定：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;FCN的结合作为unary function的结果&lt;/li&gt;&lt;li&gt;FCN的结果作为pairwise function中的Q函数的初始值。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样FCN和CRF就连起来了。下面我们还要解决一个问题，就是为什么是CRFasRNN？&lt;/p&gt;&lt;p&gt;在这篇模型结合的论文中，作者将CRF的求解过程转换成了RNN的形式。由于CRF的求解算法是迭代进行的，因此把算法展开，我们可以将其变成RNN的形式，这里的细节在此就不多说了，大家看看论文基本就能看懂。&lt;/p&gt;&lt;h2&gt;实现&lt;/h2&gt;&lt;p&gt;下面就来看看他的具体实现：&lt;a href="https://github.com/torrvision/crfasrnn" data-editable="true" data-title="GitHub - torrvision/crfasrnn: This repository contains the source code for the semantic image segmentation method described in the ICCV 2015 paper: Conditional Random Fields as Recurrent Neural Networks. http://crfasrnn.torr.vision/" class=""&gt;GitHub - torrvision/crfasrnn: This repository contains the source code for the semantic image segmentation method described in the ICCV 2015 paper: Conditional Random Fields as Recurrent Neural Networks. http://crfasrnn.torr.vision/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我们先来看看它的prototxt，我们可以用下面这张图表示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6aca12386083603e198cff5c9e6f3f05.jpg" data-rawwidth="960" data-rawheight="1280"&gt;&lt;p&gt;可以看出网络的主体部分是由之前的FCN组成。在前面的FCN中我们没有介绍其实现，这里我们就详细看下它的实现。我们从图的左上角出发，到图的左下角，然后再返回到右上角。前面全部是卷积、relu和maxpooling这几部分，后面是不同scale的结果融合。这里详细地展示了这一部分的维度内容。&lt;/p&gt;&lt;p&gt;从实现中，我们可以看出一些值得深思的细节。&lt;/p&gt;&lt;p&gt;首先是一开始的padding=100。为了不让最终的feature map太小，添加一个较大的padding是十分必要的。&lt;/p&gt;&lt;p&gt;其次就是最后一层的MULTI_STAGE_MEANFIELD，这一层我们需要特别介绍一下，虽然在文章中作者提到了CRF as RNN的概念，但是实际上它的实现并没有用RNN的框架，当然Caffe里面并没有这里可用的RNN。这里是将所有的CRF的内容集成到了一个层中，所以这一层会比较复杂，计算量也比较大，其中的反向传播也比较复杂。&lt;/p&gt;&lt;p&gt;首先我们将算法的流程图展示出来：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-0891a04ad4133d9440e5bd97ae8d98fe.jpg" data-rawwidth="960" data-rawheight="1280"&gt;&lt;p&gt;可以看出，这其中的计算主要涉及到两个类别—— MultiStageMeanfieldLayer和MeanfieldIteration，其中的MultiStageMeanfieldLayer类主要负责算法内容的组织，而其中的MeanfieldIteration类主要负责迭代计算过程。这些内容我们都可以从上面的图中读出。&lt;/p&gt;&lt;p&gt;可以看出这其中的细节除了计算高斯滤波部分的Permutohedral比较复杂，属于超纲内容，其他的部分相对比较好理解。关于Permutohedral部分的细节，有机会我们可以开一个CV系列的文章另行讲解。&lt;/p&gt;&lt;p&gt;MeanfieldIteration的反向操作实际上并不复杂，只要记得把这些过程拆解成一个个小部分慢慢算梯度就好，而MultiStageMeanfieldLayer的反向操作也只是把MeanfieldIteration的反向结果合并起来，具体细节可以去看看源码，这里我们就不再赘述了。&lt;/p&gt;&lt;p&gt;到这里，我们已经实现了将CNN和CRF无缝连接起来了。比起之前的单独由CNN组成的FCN，我们已经有了很大的进步。&lt;/p&gt;&lt;p&gt;到这里，实际上我们花了很大的力气在介绍CRF和无向概率图模型的内容，但是我们终于把这部分的内容讲完了。让我休息一下……&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22795755&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 29 Nov 2016 21:10:02 GMT</pubDate></item><item><title>FCN(5)——DenseCRF推导</title><link>https://zhuanlan.zhihu.com/p/22464569</link><description>&lt;p&gt;经过前两篇文章，我们了解了CRF的基本概念，了解了许许多多的CRF模型，也了解了Mean field variational inference的基本概念，那么这一回我们开始真刀真枪地进行公式推导。其实公式推导的部分在论文的补充材料里有，但是不够详尽，这里我们尽可能地补充一下，让推导过程更加完整。&lt;/p&gt;&lt;h2&gt;DenseCRF&lt;/h2&gt;&lt;p&gt;前面我们已经看过了DenseCRF的能量函数，如下所示&lt;/p&gt;&lt;equation&gt;E(x)=\sum_i \psi _u(x_i)+\sum_{i&amp;lt;j}\psi_p(x_i,x_j)&lt;/equation&gt;&lt;p&gt;其他内容在这就不说了，我们抓紧时间推导。&lt;/p&gt;&lt;h2&gt;Variational Inference推导&lt;/h2&gt;&lt;p&gt;我们首先给出denseCRF的Gibbs分布：&lt;/p&gt;&lt;equation&gt;P(X)=\frac{1}{Z}\tilde{P}(X)=\frac{1}{Z}exp(\sum_i \psi_u(x_i) + \sum_{i &amp;lt; j}\psi_p(x_i,x_j))&lt;/equation&gt;&lt;p&gt;下面给出KL散度部分的推导，其实就是补充材料中的推导，搬运工来了……&lt;equation&gt;D(Q||P)=\sum_x{Q(x)log(\frac{Q(x)}{P(x)})}&lt;/equation&gt;&lt;equation&gt;=-\sum_xQ(x)logP(x)+\sum_xQ(x)logQ(x)
&lt;/equation&gt;&lt;equation&gt;=-E_{X\in Q}[logP(X)]+E_{X\in Q}[logQ(X)]
&lt;/equation&gt;&lt;equation&gt;=-E_{X\in Q}[log\tilde{P}(X) ]+E_{X \in Q}[logZ]+\sum_iE_{X_i \in Q}[logQ_i(X_i)]&lt;/equation&gt;&lt;/p&gt;&lt;equation&gt;=-E_{X \in Q}[log \tilde{P}(X)]+logZ+\sum_iE_{X_i \in Q_i}[logQ_i(X_i)]&lt;/equation&gt;&lt;p&gt;由于我们要求的是Q，而logZ项中没有Q，所以这一项可以省略。&lt;/p&gt;&lt;p&gt;同时Q还需要满足：&lt;/p&gt;&lt;equation&gt;\sum_{x_i}Q_i(x_i)=1&lt;/equation&gt;&lt;p&gt;所以利用拉格朗日乘子法，可以得到&lt;equation&gt;L(Q_i)=-E_{X_i \in Q}[log \tilde{P}(X)]+\sum_iE_{x_i \in Q_i}[logQ_i(x_i)]+\lambda(\sum_{x_i}Q_i(x_i)-1)&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;这个公式的后面两项相对比较简单，但是前面一项比较复杂，我们单独做一下处理：&lt;/p&gt;&lt;equation&gt;-E_{X_i \in Q}[log \tilde{P}(X)]=-\int{\prod_i{Q_i(x_i)}[log \tilde{P}(X)]dX}&lt;/equation&gt;&lt;equation&gt;=-\int{Q_i(x_i) \prod_{i}{Q(\bar{x}_{i})}[log \tilde{P}(X)]dx_id\bar{X}}&lt;/equation&gt;&lt;equation&gt;=-\int{Q_i(x_i)E_{\bar{X} \in Q}[log \tilde{P}(X)]dx_i}&lt;/equation&gt;&lt;p&gt;经过上面的公式整理，我们可以求出偏导，可得&lt;/p&gt;&lt;equation&gt;\frac{\partial L(Q_i)}{\partial Q_i(x_i)}=-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)]-logQ_i(x_i)-1+\lambda&lt;/equation&gt;&lt;p&gt;令偏导为0，就可以求出极值：&lt;/p&gt;&lt;equation&gt;Q_i(x_i)=exp(\lambda-1)exp(-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)])&lt;/equation&gt;&lt;p&gt;由于每一个Q的&lt;equation&gt;exp(\lambda-1)&lt;/equation&gt;都相同，我们将其当作一个常数项，之后在renormalize的时候将其抵消掉，于是Q函数就等于：&lt;/p&gt;&lt;equation&gt;Q(x_i)=\frac{1}{Z_1}exp(-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)])&lt;/equation&gt;&lt;p&gt;我们将文章开头关于&lt;equation&gt;\tilde{P}&lt;/equation&gt;的定义带入，就得到了&lt;/p&gt;&lt;equation&gt;Q(x_i)=\frac{1}{Z_1}exp(-E_{\bar{X} \in Q}[(\sum_i \psi_u(x_i) + \sum_{j \neq i}\psi_p(x_i,x_j)) | x_i])&lt;/equation&gt;&lt;p&gt;这里面xi的由于是已知的，所以我们可以得到补充材料里的结果（但是变量名不太一样）：&lt;/p&gt;&lt;equation&gt;Q_i(x_i=l)=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{j \neq i}E_{\bar{X} \in Q_j}\psi_p(l,X_j)]&lt;/equation&gt;&lt;p&gt;继续扩展，就可以得到&lt;/p&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{m=1}^Kw^{(m)}\sum_{j \neq i}E_{X \in Q_j}[\mu(l,X_j)k^{(m)}(f_i,f_j)]]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{m=1}^Kw^{(m)}\sum_{j \neq i}\sum_{l' \in L}Q_j(l')\mu(l,l')k^{(m)}(f_i,f_j)]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{l' \in L}\mu(l,l')\sum_{m=1}^Kw^{(m)}\sum_{j \neq i}Q_j(l')k^{(m)}(f_i,f_j)]&lt;/equation&gt;&lt;p&gt;这样，一个类似message passing的公式推导就完成了。其中最内层的求和可以用截断的高斯滤波完成。搬运最后的一点公式，可以得：&lt;/p&gt;&lt;equation&gt;\tilde{Q_i^{(m)}(l)}=\sum_{j \neq i}Q_j(l')k^{(m)}(f_i,f_j)=\sum_{j}Q_j(l)k^{(m)}(f_i,f_j)-Q_i(l)&lt;/equation&gt;&lt;p&gt;上面公式的第一项可以转化成卷积操作。&lt;/p&gt;&lt;p&gt;完成了这些推导，下面我们暂时不给出denseCRF的单独结果，我们下面看看FCN和DenseCRF结合的效果，FCN已经等的花都谢了……&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464569&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 22 Nov 2016 21:58:11 GMT</pubDate></item><item><title>无痛的机器学习第一季目录</title><link>https://zhuanlan.zhihu.com/p/22464594</link><description>经过5个月的努力，我终于完成了40篇不高不低还算有些干货的机器学习文章。回首看看这5个月的努力，每一次的写作都充满了开心与痛苦。说开心是因为当自己完成每一个章节的写作后，自己感觉对这一部分的知识有了更加深刻地认识，而痛苦则是对写作过程中一系列事情的恐惧——找不到好选题，对论文细节的困惑，跑不出想要的结果，难以用通俗易懂的语言描述自己所知……好在这一切就要告一段落了。&lt;p&gt;以下就做一个集合贴，展示一下这一季的所有文章，对本专栏文章感兴趣的童鞋，收藏这一篇就足够了（后续未发布的几篇和番外篇会更新上来）：&lt;/p&gt;&lt;h2&gt;文章目录&lt;/h2&gt;&lt;h2&gt;CNN网络基础结构&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21525237" data-editable="true" data-title="神经网络-全连接层（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21535703" data-editable="true" data-title="神经网络-全连接层（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21572419" data-editable="true" data-title="神经网络-全连接层（3） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（3）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21609512" data-editable="true" data-title="卷积层（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（1） &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21675422" data-editable="true" data-title="卷积层（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（2） &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21737674" data-editable="true" data-title="卷积层（3） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（3）&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN网络上层结构&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22197188" data-editable="true" data-title="CNN——架构上的一些数字 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN——架构上的一些数字&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22214112" data-editable="true" data-title="CNN--结构上的思考 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN--结构上的思考 &lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Caffe源码分析&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21796890" data-editable="true" data-title="Caffe代码阅读——层次结构 " class=""&gt;Caffe代码阅读——层次结构 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21875025" data-editable="true" data-title="Caffe源码阅读——Net组装 - 无痛的机器学习 - 知乎专栏" class=""&gt;Caffe源码阅读——Net组装 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21800004" data-editable="true" data-title="Caffe代码阅读——Solver - 无痛的机器学习 - 知乎专栏" class=""&gt;Caffe代码阅读——Solver &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22260935" data-editable="true" data-title="CNN--两个Loss层计算的数值问题 " class=""&gt;CNN--两个Loss层计算的数值问题 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22404295" data-editable="true" data-title="Caffe源码阅读——DataLayer " class=""&gt;Caffe源码阅读——DataLayer&amp;amp;Data Transformer&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;生成网络&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22386494" class="" data-editable="true" data-title="DCGAN的小尝试（1）"&gt;DCGAN的小尝试（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22389906" class="" data-title="DCGAN的小尝试（2）" data-editable="true"&gt;DCGAN的小尝试（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464760" class="" data-editable="true" data-title="VAE（1）——从KL说起"&gt;VAE（1）——从KL说起&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464764" class="" data-editable="true" data-title="VAE(2)——基本思想"&gt;VAE(2)——基本思想&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464768" class="" data-editable="true" data-title="VAE(3)——公式与实现"&gt;VAE(3)——公式与实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22684931" class="" data-editable="true" data-title="VAE（4）——实现"&gt;VAE（4）——实现&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;优化算法&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21486804" data-editable="true" data-title="梯度下降是门手艺活…… - 无痛的机器学习 - 知乎专栏" class=""&gt;梯度下降是门手艺活…… &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21486826" data-editable="true" data-title="路遥知马力——Momentum - 无痛的机器学习 - 知乎专栏" class=""&gt;路遥知马力——Momentum &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22099871" data-editable="true" data-title="CNN——L1正则的稀疏性 " class=""&gt;CNN——L1正则的稀疏性 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464537" class="" data-editable="true" data-title="Caffe中的SGD的变种优化算法(1)"&gt;Caffe中的SGD的变种优化算法(1)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464551" class="" data-editable="true" data-title="Caffe中的SGD的变种优化算法(2)"&gt;Caffe中的SGD的变种优化算法(2)&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN可视化&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22245268" data-editable="true" data-title="CNN-反卷积（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN-反卷积（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22293817" data-editable="true" data-title="CNN-卷积反卷积（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN-卷积反卷积（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464575" class="" data-editable="true" data-title="寻找CNN的弱点"&gt;寻找CNN的弱点&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN数值&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22027076" data-editable="true" data-title="CNN的数值实验 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN的数值实验 - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22028079" data-editable="true" data-title="CNN数值——xavier（上） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——xavier（上） - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22044472" data-editable="true" data-title="CNN数值——xavier（下） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——xavier（下） - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22148777" data-editable="true" data-title="CNN数值——ZCA - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——ZCA - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;FCN&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464571" class="" data-editable="true" data-title="FCN(1)——从分类问题出发"&gt;FCN(1)——从分类问题出发&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464581" class="" data-title="FCN(2)——CRF通俗非严谨的入门" data-editable="true"&gt;FCN(2)——CRF通俗非严谨的入门&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464586" class="" data-editable="true" data-title="FCN(3)——DenseCRF"&gt;FCN(3)——DenseCRF&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22887466" class="" data-title="FCN(4)——Mean Field Variational Inference" data-editable="true"&gt;FCN(4)——Mean Field Variational Inference&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Representation&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/23444100" class="" data-editable="true" data-title="CenterLoss——实战&amp;amp;源码"&gt;CenterLoss——实战&amp;amp;源码&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;GPU&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21908564" data-editable="true" data-title="[翻译]Exploring the Complexities of PCIe Connectivity and Peer-to-Peer Communication - 无痛的机器学习 - 知乎专栏" class=""&gt;[翻译]Exploring the Complexities of PCIe Connectivity and Peer-to-Peer Communication - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;“聊点轻松的”系列&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21788777" class="" data-editable="true" data-title="聊点轻松的——划个水"&gt;聊点轻松的——划个水&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22112582" data-editable="true" data-title="聊点轻松的2——斗图篇"&gt;聊点轻松的2——斗图篇&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22421787" data-editable="true" data-title="聊点轻松的3——什么是学习"&gt;聊点轻松的3——什么是学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22842859" data-editable="true" data-title="聊点轻松的4——这回真的很轻松"&gt;聊点轻松的4——这回真的很轻松&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23750864" class=""&gt;聊点轻松的5——这篇写得并不轻松&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464594&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 17 Nov 2016 23:48:39 GMT</pubDate></item><item><title>聊点轻松的5——这篇写得并不轻松</title><link>https://zhuanlan.zhihu.com/p/23750864</link><description>没错，又是熟悉的开头，不知不觉，我的知乎小庙迎来了5000名看官，已经快过去半年了，每招来1000名看官我就写一篇扯蛋的文章，之前我已经尽力把能扯的内容都扯过了，还把自己不擅长的内容也强扯了（最后果然被打脸了）。但是一切还算顺利，总之感谢大家的支持！这一篇我准备硬扯一下了。&lt;p&gt;在我中学的时候，我对武侠小说异常地痴迷，并且自己撸起袖子写过武侠小说。武侠小说之中，还是最喜欢金庸老先生的小说。而且因为看三联版的原因，我对40这个数字十分喜欢，因为金老先生的小说中有不少被归纳成40章节——比方说射雕三部曲，笑傲江湖。于是我也想着自己可以写出几个“40”来。&lt;/p&gt;&lt;p&gt;于是乎，自己的第一个技术类的40篇就要完结了，也可以说《无痛的机器学习》第一季就要告一段落了（实际上已经写完了，只是为了效果按期放出）。这一季结束后，我会按时间放出一些番外篇的文章，第二季的新鲜文章将在2017年正式放出了。&lt;/p&gt;&lt;p&gt;另外我发现了一个现象，不知道这个现象只发生在我这里还是在知乎中比较普遍的现象，那就是大家更喜欢点“收藏”而不是点“赞”。对我来说大家点哪个都一样，但是说实话一篇篇文章的收藏实在有点累，所以我会在这篇文章后面再一篇这一季文章的目录文，喜欢收藏的朋友直接收藏这一篇就好。传送门：&lt;a href="https://zhuanlan.zhihu.com/p/22464594"&gt;https://zhuanlan.zhihu.com/p/22464594&lt;/a&gt;&lt;/p&gt;&lt;p&gt;写完了这一季，我能感受到自己的成长，对于技术细节的理解，对于技术流程的表述，这些能力还是有了很大的提升。作为机器学习界的一名小学生，我正在茁壮成长。在这一路上要感谢的人很多：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;感谢帮我审阅文章的&lt;a href="https://www.zhihu.com/people/03675ab7bf1c28d3d71d2154abb3ddd1" data-hash="03675ab7bf1c28d3d71d2154abb3ddd1" class="member_mention" data-editable="true" data-title="@我爱机器学习" data-hovercard="p$b$03675ab7bf1c28d3d71d2154abb3ddd1"&gt;@我爱机器学习&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/08cd1d56513335b13d6a93725db969ad" data-hash="08cd1d56513335b13d6a93725db969ad" class="member_mention" data-title="@夏龙" data-editable="true" data-hovercard="p$b$08cd1d56513335b13d6a93725db969ad"&gt;@夏龙&lt;/a&gt;，他们在第一时间帮我指出文章中不足之处；&lt;/li&gt;&lt;li&gt;感谢很多在评论中指出文章问题的朋友，是你们让这些文章变得更加正确；&lt;/li&gt;&lt;li&gt;同时也感谢评论中提问题的朋友，你们中的一些问题我一开始也是并不清楚的，回答这些问题也是一个提高的过程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之前我写过一篇讨论学习的文章，聊过对学习的一些看法，在我看来，在学习机器学习的过程中，要我感到成长最快的就是读源码，做实验。很多时候别人的论文，别人写的技术博客很精彩，但是如果没有动手实践，就总感觉理解得不够透彻明白。而真正看到源代码的实现细节后，我才能明白论文博客中没有着重提到的一些奥妙。&lt;/p&gt;&lt;p&gt;最后，我也想向各位看官征集一下，大家接下来对哪些技术内容感兴趣呢？我会挑选一些大家感兴趣且我能写的内容（原因在这里：&lt;a href="https://www.zhihu.com/question/26865557/answer/126145134" class=""&gt;https://www.zhihu.com/question/26865557/answer/126145134&lt;/a&gt;），尽可能地为大家呈现出来。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23750864&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 17 Nov 2016 23:47:08 GMT</pubDate></item><item><title>FCN(4)——Mean Field Variational Inference</title><link>https://zhuanlan.zhihu.com/p/22887466</link><description>&lt;p&gt;上一篇我们介绍了DenseCRF的形式，我们已经了解了denseCRF，下面我们花一点时间了解下denseCRF的求解方式——Mean Field Variational Inference&lt;/p&gt;&lt;h2&gt;Variational Inference入坑&lt;/h2&gt;&lt;p&gt;前面我们在介绍Variational autoencoder的时候刚刚提到过这种求解复杂模型的方法，不过在VAE那里我们只是借着它的坑做了一个简单的展开，而且VAE的计算和Variational Inference的关系并不算特别密切。而这一次我们就要用心了，因为——&lt;/p&gt;&lt;p&gt;上面的pairwise特征确实有点多……&lt;/p&gt;&lt;p&gt;另外，在前面一篇文章中我们说过，对于无向图模型，我们要先求出模型整体的联合变量，才能再做其他的打算。也就是说我们要同时把所有的像素的类别解出来，这个解空间实在有点大，如果我们想用暴力的方法求解，恐怕要吃苦头——比方说MCMC。&lt;/p&gt;&lt;p&gt;于是我们这里采用Mean field variational approximation的方法求解。那么什么是Mean field呢？其实我对这个高深的物理理论也不是特别了解（说实话，我读的本科专业没有大学物理课，所以物理水平基本停留在高中水平，勿喷……），但是我们可以用一个稍微形象的方式来理解。&lt;/p&gt;&lt;p&gt;通过前面的学习，我们知道无向图模型中的一些类似概率的表示可以用factor或者feature表示。由于我们每一对像素之间都有一条边相连，如果我们把每一条边用一个factor表示出来，那么这张无向图上就会布满factor。我们假设一个像素的energy发生了变化，那么所有与它相连的像素点——当然就是剩下的所有像素点都有可能随着这个像素点发生变化。&lt;/p&gt;&lt;p&gt;于是乎，可怕的蝴蝶效应就开始了。所有的像素点中，可能有些像素点的energy伴随着发生了变化，那么所有连着它们的像素点——抱歉，这回又是所有像素点，会跟着它们继续发生变动，于是这个过程会持续不断地进行，直到它们都玩累了，玩不动了，enregy保持不变了，这个游戏才算结束。&lt;/p&gt;&lt;p&gt;下面这个问题就抛给我们了——我们建立的模型具有非常强大的建模能力，但是也具有如此有尿性的能量传播特性，如果让我们自己去把这些energy传导的过程模拟出来，感觉是要死人的……没错是要死人的……&lt;/p&gt;&lt;p&gt;我们可以把所有的连接两个像素点的factor想象成一根弹簧，把像素点想象成可以有一定限度位移的小球。当有一个小球稍微动了一下，所有连着它的弹簧会发生震动，那么弹簧另一边的小球也会跟着动，于是顺着弹簧，所有球都被传导起来，大家一起动起来……好吧，我是希望用一个更容易想象出来、有画面感的例子让大家感受一下这个复杂模型的恐怖性。&lt;/p&gt;&lt;p&gt;下面我们就要祭出我们的Mean field大招了。我们的Mean field approximation帮助我们把这个问题进行了简化，问题变成了这个样子——&lt;/p&gt;&lt;p&gt;我们要将每一个小球受到别的小球的弹簧力一次性计算完。&lt;/p&gt;&lt;p&gt;这话说得实在有些抽象，我们用更加详细的语言表达一下。我们刚才描述了那个混乱的力传导的场景，下面由上帝出马来调节这些力，上帝喊口号，所有小球听从指挥，准备！&lt;/p&gt;&lt;p&gt;第一步，小球如果你想动，你就动一下。注意！你的动作先别传递到弹簧上，上帝我这有一个小本本，我先记下来，一会儿我会按本子上记录的计量用我的魔法施加到这些弹簧上的。放心，你的力会原封不动的送上去，不会打折扣的。&lt;/p&gt;&lt;p&gt;第二步，上帝施展分解大法，把整个模型拆解开来，有多少个小球就有多少个子模型。在每一个子模型里，只有一个小球是主角，所有和这个小球相连的弹簧可以保留，所有和这个小球无关的弹簧全部被上帝拆掉。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-09fbb752a0e9aeb94c6b0cef6cca2bdd.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;第三步，上帝拿出刚才的小本本，把每个球的力施加到每一个子模型的弹簧上。听上去好像要做的工作很多，不过谁让他是上帝呢，能者多劳嘛。&lt;/p&gt;&lt;p&gt;第四步，不用说这个时候，每个子模型的主角——那个集万千弹簧于一身的小球受到了成吨的力，OK，尽情地享受弹簧传来的力道吧！&lt;/p&gt;&lt;p&gt;第五步，这些主角在享受完弹簧传来的力道，心想来而不往非礼也，我也得传点力回去啊，于是准备扭扭屁股动动身子传点力回去的。这时候上帝突然出现，放出大招，这些主角竟然无法把自己受到的力传回去。说好的雨露均沾呢，我得把力传回去啊，上帝你不能管得太多啊。不过上帝知道，在它们的另一个平行世界——也就是别的子模型中，自己最初移动产生的力也已经传递给别的“主角”了。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5e11f3eae1294b1978832b230f6cce81.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;第六步，上帝施展大法，将所有的子模型合成原来的模型。这样我们的一次力的传递过程就结束了。不过瘾，还想再来一波？好，那我们回到第一步……&lt;/p&gt;&lt;p&gt;我们花了这么多笔墨，将这个过程大概讲了一遍，如果回来在看前面那句话——&lt;/p&gt;&lt;blockquote&gt;我们要将每一个小球受到别的小球的弹簧力一次性计算完。&lt;/blockquote&gt;没错，每一次每个小球给别的小球传的力一次性传完，别的小球的力也一次性接受完。那些二次传导的事情再我们的Mean Field中就没有了。大家瞬间感到了一丝轻松，听上去这个模型有解出来的希望了啊。&lt;p&gt;好了，那么Variational Inference的目标，就是用这个简化后的这个模型尽可能地靠近原来那个复杂的模型。如果两个模型能完全一样，那就太好了，我们有简单的模型来手，还要复杂的模型干啥？赶紧扔了。&lt;/p&gt;&lt;p&gt;那么下面的目标就是定义一个目标函数，目标是让这个简单模型和复杂模型靠近。前面我们在介绍VAE的时候曾经提到过——没错，就是KL散度。下面我们同样用KL散度来表示这个目标函数。&lt;/p&gt;&lt;p&gt;时间不早了，下一回我们来看看这个算法的真面目。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22887466&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 15 Nov 2016 22:43:52 GMT</pubDate></item><item><title>FCN(3)——DenseCRF</title><link>https://zhuanlan.zhihu.com/p/22464586</link><description>上一回我们简单介绍了无向图模型和CRF的基本概念，下面我们来看看CRF在图像分割问题上的具体应用。我们简单回忆一下CRF中的两个关键变量，这时我们需要换一下变量的名称——我们用I表示图像的像素信息，也就是观察变量，我们用X表示图像中每一个像素的类别，也就是我们想要知道的信息。不过在更多的文档中，大家喜欢用X表示图像上的像素，用Z表示我们想求的label。&lt;p&gt;好了，为了更好地展示我们提到的模型，我们给出一个简单的图形：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-360800edde6ab9f08091e2e835d0880e.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;下面的就是我们建模的过程了，最简单的建模方式就是每一个像素的类别只和自己所在的像素有关。我们可以用一个简单的图来表示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d8707af25b5b9b9829828d346e8a414d.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;这个图看上去比较简单吧，而且计算也比较简单。我们可以建一个模型，输入是一个像素的特征，输出是一个像素所代表的类别。那么这个模型和一般的分类问题没有太多区别。&lt;/p&gt;&lt;p&gt;不过这样的效果显然不好，谁能只通过一个像素就知道这个地方是什么类别呢？这个模型虽然简单好解，但是我们一眼就可以看出，它并不是一个高级的模型，所以这个模型pass了。不要问我什么理由……&lt;/p&gt;&lt;p&gt;下面我们再来一个模型，每一个像素的类别和所有像素的图像信息有关，这个模型实际上就和FCN的输出相同，我们可以用下面的图表示这个模型：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1cb88462ccca65f855d2320c07c64e53.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;CNN模型虽然很强大，但是CNN模型缺少一个关键点，就是每一个像素点类别之间实际上存在着一定关系，也就是我们常说的图像的平滑性——每一个图像像素点的类别都有可能和临近点的类别相近，这个特性是CNN模型所不具有的。所以我们对这个模型也保留意见。&lt;/p&gt;&lt;p&gt;于是我们新鲜出炉的新模型又来了——这一次我们让每一个像素点的类别和它的4邻域的类别相关，于是它的模型变成了这个样子：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-652eb608631d3581d89680220b6dbd55.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;这个模型瞬间高大上了许多，我们前面提到的平滑性已经得到了一定的满足。但是有时候仅仅是这种程度的关联是不够的，如果临近的几个像素恰好产生了一点波动，不是我们想要的那个样子，那么这个像素点的类别就有可能出问题。我们还需要更深层次的关联。于是乎，传说中的denseCRF就诞生了。&lt;/p&gt;&lt;p&gt;denseCRF的模型是什么样子呢？如下图所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-46beab9f4805ca1b8ac1699775533650.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;好吧，基本上能连在一起的都连在一起的，我们把模型的复杂程度提到了最高的程度，完全成了一团乱麻了……&lt;/p&gt;&lt;h2&gt;Dense CRF&lt;/h2&gt;&lt;p&gt;我们看过了它的模型形式，下面直接来看看模型的能量函数表达形式：&lt;/p&gt;&lt;equation&gt;E(x)=\sum_i \psi _u(x_i)+\sum_{i&amp;lt;j}\psi_p(x_i,x_j)&lt;/equation&gt;&lt;p&gt;可以看出每一个像素都有一个unary的函数，也就是说在这个特征函数里w，剩下的参数都出现在图像的像我们只考虑当前像素的类别，而暂时不考虑别的像素的类别信息。&lt;/p&gt;&lt;p&gt;而后面的pairwise函数里，每一个像素的类别都和其他像素计算一个energy feature。于是就有了上面的公式形式。注意这里的能量函数是所有像素点的联合能量和不是某一个像素点的能量，所以后面的pairwise项，我们有n(n-1)/2组特征，总的来说，特征数量是像素数量的平方级别，如果我们有一张100万像素的图片，那么我们就会建立4950亿组pairwise特征。正是因为这种复杂的形式，所以这个模型被称作Dense CRF。满满的全是dense啊！&lt;/p&gt;&lt;p&gt;关于unary函数的内容，我们可以尽情发挥，在denseCRF中我们并没有对这一部分做详细的限制。因此关于这部分我们就暂时略去不谈了，在后面的文章中我们会重新回来，挖掘unary函数的潜力。下面我们专注于解决pairwise这个大坑。&lt;/p&gt;&lt;p&gt;下面我们讲piarwise部分展开，其中&lt;/p&gt;&lt;equation&gt;\psi_p(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^Kw^{(m)}k^{(m)}(f_i,f_j)&lt;/equation&gt;&lt;p&gt;可以看出，pairwise函数中还是比较复杂的，我们从左往右以此介绍。&lt;/p&gt;&lt;p&gt;首先是&lt;equation&gt;\mu(x_i,x_j)&lt;/equation&gt;，这一项被称作label compatibility项，简单来说这里约束了“力”传导的条件，只有相同label条件下，能量才可以相互传导。具体来说，“一个像素可能是飞机”的能量可以和“另一个像素可能是飞机”的能量相互传导，从而增加或者减少后者“可能是飞机”的能量，从而影响“可能是飞机”的概率，而“一个像素可能是飞机”的能量是不能影响“另一个像素是人”的概率的。&lt;/p&gt;&lt;p&gt;文章中也提到了，这个简单地一刀切似乎有点不人性。拿Pascal-VOC中的20类+背景类来说，有些类别之间的相似性是很强的，而另外一些类别则完全不相似，所以作者后面提到了一些学习相关的事情，这里我们就不再深入下去了。&lt;/p&gt;&lt;p&gt;加和项里面就是经典的权重*feature的套路了，其中&lt;/p&gt;&lt;equation&gt;k^{(m)}(f_i,f_j)=w^{(1)}exp(-\frac{|p_i-p_j|^2}{2\theta_{\alpha}^2}-\frac{|I_i-I_j|^2}{2\theta_{\beta}^2})+w^{(2)}exp(-\frac{|p_i-p_j|^2}{2\theta_{\gamma}^2})&lt;/equation&gt;&lt;p&gt;这一项以特征的形式表示了不同像素之前的“亲密度”。前面我们提到了特征不同于tabular形式的factor，我们看不到表格，只能看到公式。上面的公式中，第一项被称作appearance kernel，第二项被称作smooth kernel。这里面有很多变量，我们一一来看。&lt;/p&gt;&lt;p&gt;appearance kernel里面的p表示像素的位置——position，我们的图像是2维的，那么position就有2维。I表示图像的像素值——Intensity，我们的图像是彩色的，那么Intensity就有3维。分式下面的两个参数无论从位置还是长相都像高斯分布中的方差，这里的含义也差不多的。&lt;/p&gt;&lt;p&gt;于是乎我们可以看出，如果两个像素距离近且颜色近，那么这个feature特征就会很强，反之则不强。同时分母也控制了强弱性，分母越大越难强起来。其实这一项和图像处理中的bilateral filter很像。我们相当于在一个5维的空间内寻找相近的像素对并给予它们的特征加强。&lt;/p&gt;&lt;p&gt;看完了前面一项，在看后面那一项就不会觉得太难。大家照着上面那一段话自行分析吧。&lt;/p&gt;&lt;p&gt;好了，到这里我们就交代完DenseCRF的表达形式了，下面就要进入Mean field variational inference的环节了。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;h2&gt;私货时间2&lt;/h2&gt;&lt;p&gt;恭喜川普大大！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464586&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Wed, 09 Nov 2016 20:08:16 GMT</pubDate></item><item><title>CenterLoss——实战&amp;源码</title><link>https://zhuanlan.zhihu.com/p/23444100</link><description>本来要继续连载CRF的，但是最近看到了知乎上各位大神的论文解读——《A Discriminative Feature Learning Approach for Deep Face Recognition》,其中介绍了他们设计的一个用户提高类别的区分度的损失函数——Center Loss，并且有一个基于MNist数据库的小实验，于是本人就简单实践了一下。&lt;p&gt;本着其他大神已经深度解析了这篇文章的内容，所以我觉得我再凑热闹把那些理论的东西讲一遍意义不大，倒不如抡起袖子干点实事——把代码写出来跑一跑。在我完成实验前，已经看到github上有人完成了MXNet的center loss代码，所以作为Caffe派的革命小斗士，我得抓紧时间了。&lt;/p&gt;&lt;p&gt;不说废话，先用一个8拍把问题说明白：&lt;/p&gt;&lt;h2&gt;一个8拍的center loss&lt;/h2&gt;&lt;p&gt;1：同样是分类问题，我们之前只关注了待识别的图像应该属于哪个类别，但是并没有关心一个同样重要的问题：最终分类器的分界面区域内的空间是不是都应该属于这个类别？空间内这些长得很像的图像，它们的特征会不会其实差距有点大？&lt;/p&gt;&lt;p&gt;2：于是乎作者设计了一个网络，在倒数第二层全连接层输出了一个2维的特征向量，并以此进行进一步的分类。我们把MNist的Test集合数据通过最终训练好的模型进行预测，倒数第二层的样子是这样的：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bdbd57903c0eac1e73626c340bcd487e.png" data-rawwidth="889" data-rawheight="572"&gt;嗯，貌似和论文上的图像差不多啊……&lt;/p&gt;&lt;p&gt;3：于是乎，作者就觉得，怎么每个类别的特征都是长长的一条啊？那么实际上同一个类内部的差距还很大呢……而且，同一类别下两个图像的距离可能比不同类的距离还大，这种现象如果一直存在，那么在作者关注的人脸识别领域，会不会出现一个人脸和别人的脸太相似而被误刷啊……&lt;/p&gt;&lt;p&gt;4：不能这样子，于是作者设计了一个新的loss叫center loss。我们给每个label的数据定义一个center，大家要向center靠近，离得远的要受惩罚，于是center loss就出现了：&lt;/p&gt;&lt;equation&gt;CenterLoss=\frac{1}{2N}\sum_{i=1}^N|x_i-c|^2_2&lt;/equation&gt;&lt;p&gt;5：众人纷纷表示这个思路很好，但是这个c怎么定义呢？首先拍脑袋想到的就是在batch训练的时候不断地计算更新它，每一轮我们计算一下当前数据和center的距离，然后把这个距离以某种形式——就是梯度叠加到center上：&lt;/p&gt;&lt;equation&gt;\frac{\partial CenterLoss}{\partial x}=\frac{1}{N}\sum_{i=1}^N(c-x_i)&lt;/equation&gt;&lt;p&gt;6：吃瓜群众立刻表示：每个batch的数据并不算多，这样更新会不会容易center产生抖动？数值上的不稳定在优化中是大忌啊！于是作者简单粗暴地讲：那我们加个scale，让它不要太大：&lt;/p&gt;&lt;equation&gt;\Delta c = \frac{\alpha}{N} \sum_{i=1}^N(c-x_i)&lt;/equation&gt;&lt;p&gt;这个scale肯定是小于1的。&lt;/p&gt;&lt;p&gt;7：吃瓜群众满意了，吃瓜子的群众有发话了：现在你有两个loss了，我们该怎么平衡这两个loss之间的权重呢？作者心想：你这不是明知故问么……于是又加了一个超参数&lt;equation&gt;\lambda &lt;/equation&gt;，用于控制两个loss之间的比例。&lt;/p&gt;&lt;p&gt;反正多来个超参数无所谓，你们慢慢调去吧～&lt;/p&gt;&lt;p&gt;8：该定义的终于都结束了，我们加入新的loss，训练之后得到了这个结果：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d4e7f06eb2628d4c115d3a089b4d8e69.png" data-rawwidth="859" data-rawheight="604"&gt;于是掌声雷动，这个效果看着确实不错啊～&lt;/p&gt;&lt;h2&gt;一些细节&lt;/h2&gt;&lt;p&gt;由于倒数第二层的特征维度被缩减成了2，所以识别的精度肯定会受到些影响，不过这只是为了可视化的效果，所以在真正的实验中我们可以把这个数字调大。在我的实验中最终的Test Accuracy是0.9888。比正常LeNet的0.99稍低一点。&lt;/p&gt;&lt;p&gt;直接修改LeNet倒数第二层的维度会造成无法训练，所以论文中的LeNet++使用了6层卷积。对于MNist这样的小问题使用6层卷积也是没谁了，所以训练起来还是要费点时间的。&lt;/p&gt;&lt;p&gt;在我的实验中加入center loss后Test Accuracy实际上是下降了一点的。不过这点下降并不能说明center loss对这个问题起了反作用，后面还是需要尝试当倒数第二层的维度大于2时的情况。&lt;/p&gt;&lt;h2&gt;干货来了&lt;/h2&gt;&lt;p&gt;说了这么多废话，it's time to show me the code。链接：&lt;a href="https://github.com/hsmyy/CenterLoss_Caffe_Mnist" data-editable="true" data-title="GitHub - hsmyy/CenterLoss_Caffe_Mnist: It's the script of Center loss on mnist dataset running on Caffe."&gt;GitHub - hsmyy/CenterLoss_Caffe_Mnist: It's the script of Center loss on mnist dataset running on Caffe.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;由于是快速尝试，只实现了cpu的版本，而且写得比较粗糙，望各位大神不吝赐教。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23444100&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Sat, 05 Nov 2016 18:39:21 GMT</pubDate></item><item><title>FCN(2)——CRF通俗非严谨的入门</title><link>https://zhuanlan.zhihu.com/p/22464581</link><description>&lt;p&gt;前面我们简单介绍了FCN——这个将High-Level任务转到Low-Level任务的模型。这里的High和Low并不是我们通常意义中的High和Low，两种任务并没有高低之分，但是两种任务实际上需要的技术还是有所不同的。CNN模型从High-Level任务起家，直接将它们放到Low-Level的任务中还是有些“水土不服”，于是乎，大神们想出了用概率图模型来补充这些细粒度的任务。&lt;/p&gt;&lt;p&gt;由于在这个专栏中我们还没有介绍概率图模型的基本内容，这一篇我们简单介绍下概率图模型和CRF的基本概念，为后面的内容做铺垫。&lt;/p&gt;&lt;h2&gt;无向图模型&lt;/h2&gt;&lt;p&gt;想了解无向图模型，先要了解无向图的特点。无向图和有向图有什么区别呢？不用说，就是方向嘛。那么有方向会有什么好处呢？当然就是整个概率图中概率或者信念（belief）的流动性。在有向图模型中，每一个小部分可以看作是一个CPD，也就是Conditional Probablistic Distribution。这样的局部条件概率是很有用的，但是对于无向图来说，没有了方向也就丧失了这样的优势。&lt;/p&gt;&lt;p&gt;没有方向的无向图也就没法拥有CPD了，但是无向图模型还是有自己的办法。无向图模型一个个小部分被称作Factor，像CPD一样，Factor也可以表示成tabular的形式。也就是对于几个随机变量，我们随机变量的某个赋值会对应一个实数。但是factor有一个特点，那就是一个factor内容没有和为1的约束。&lt;/p&gt;&lt;p&gt;没有和为1的约束？Are you kidding？当然不是kidding。如果我们想求解概率还是有方法的，那就是把所有的Factor像有向图模型的贝叶斯网络那样都乘起来，再做一个归一化。我们就得到了总体的联合概率。得到了联合概率，就不用担心得到那些marginal probabilities和conditional probabilities了。这样无向图模型和有向图模型又走到同一起跑线。&lt;/p&gt;&lt;p&gt;那么问题又来了？为什么无向图模型不像有向图模型学习，也用CPD表示一个个的子部分，而要使用一个新东西呢？实际上有向图模型并不能够表示所有的真实场景，有向图模型通常需要一个有顺序的推断过程，其中的一些依赖关系和独立关系是有限制的，而无向图模型就没那么多限制了。所以说无向图模型可以对更多的问题进行建模。但是放弃了方向，也就意味着放弃了条件依赖和一些条件独立的特性，于是我们只能用Factor的形式进行表示。&lt;/p&gt;&lt;p&gt;当然Factor也有自己的好处，因为没有和为1的限制，所以整体上它的数值要求不是那么严格。但是它也有自己的坏处，那就是我们从Factor的Tabular形式中想读出一些有价值的信息是比较困难的。这个困难有两个方面：&lt;/p&gt;&lt;p&gt;首先，因为不具有和为1的限制，所以我们想计算联合概率就比较抽象。这个大家去看几个真实的Factor就能明白了。再看看贝叶斯网络的CPD，你就会感慨还是CPD写的清楚啊。&lt;/p&gt;&lt;p&gt;其次，Factor的Tabular中记述的一些关系和全局状态下的一些关系有时是相反的。我们具体看某个Factor时，会觉得这些随机变量更有可能产生某几个数值，但是如果我们站在全局观察，把联合概率计算出来再去计算marginal probability，就会发生局部的关系可能是错误的。而CPD在这方面具有优势，局部的概率放在全局还是合理的。&lt;/p&gt;&lt;p&gt;说实话前面的知识量还是有点大，但是上面的就是无向图模型的基础，总结起来就是这些。&lt;/p&gt;&lt;h2&gt;Gibbs Distribution&lt;/h2&gt;&lt;p&gt;Gibbs Distribution就是利用Factor表示的无向图模型的概率分布，Gibbs Distribution的表示形式如下所示：&lt;/p&gt;&lt;equation&gt;P(X_1,X_2,...X_n)=\frac{1}{Z(X)}\tilde{P(X_1,X_2,...X_n)}&lt;/equation&gt;&lt;equation&gt;\tilde{P(X_1,X_2,...X_n)}=\prod_{i=k}^m\phi_i(X)&lt;/equation&gt;&lt;equation&gt;Z(X)=\sum \prod \phi_i(X)&lt;/equation&gt;&lt;p&gt;这也就是利用无向图模型表示联合概率的方式。&lt;/p&gt;&lt;h2&gt;Log-Linear Model&lt;/h2&gt;&lt;p&gt;上面的Gibbs Distribution实际上已经可以用了，但是它并不是十分好用。为什么呢？因为每一个Factor实际上还是需要采用Tabular的形式进行表达，这对我们建模还是个不小的负担。所以我们需要将这个形式进行一定的转换。&lt;/p&gt;&lt;p&gt;我们重新定义Factor：&lt;/p&gt;&lt;equation&gt;\phi(X)=exp(-\xi(X))&lt;/equation&gt;&lt;equation&gt;\xi(X)=-log(\phi(X))&lt;/equation&gt;&lt;p&gt;我们把&lt;equation&gt;\phi(X)&lt;/equation&gt;称作Factor function，把&lt;equation&gt;\xi(X)&lt;/equation&gt;称作Energy Function。在物理学中，能量越大的物质存在的概率越小，这样也可以解释这个崭新登场的函数。&lt;/p&gt;&lt;p&gt;为什么要定义这个函数呢？我们知道Factor function中的每一项都需要是非负的，这个限制也会对我们的建模造成困扰，因此利用指数，我们的Energy Function拜托了非负数的限制，现在变得可正可负。&lt;/p&gt;&lt;p&gt;另外一个十分重要的特性，是我们把原来的乘法关系变成了加法关系。我们现在有&lt;/p&gt;&lt;equation&gt;\tilde{P(X_1,X_2,...X_n)}=exp(\sum_{i=k}^m\xi_i(X))&lt;/equation&gt;&lt;p&gt;变成加法关系对我们建模求解来说都是一个令人兴奋的事情，因为加法的关系更利于求导化简。当然，模型形式到了这一步还不够，我们还要做进一步的化简，那就是引入Feature这个概念。&lt;/p&gt;&lt;p&gt;我们知道Factor的一般形式是Tabular的形式，但是很多时候我们的Tabular实际上是比较稀疏的。虽然参与一个Factor的随机变量很多，但是真正有意义的关系其实没几个。所以我们希望放弃Tabular的形式，转而使用Feature的形式进行表示，说白了就是尽可能地合并相同结果的表示条件。这样的话Factor的表示就会简洁很多。&lt;/p&gt;&lt;p&gt;于是我们就完成线性模型的构建。&lt;/p&gt;&lt;p&gt;CRF&lt;/p&gt;&lt;p&gt;CRF的全称是Conditional Random Field。它的形式如下所示：&lt;/p&gt;&lt;equation&gt;P(Y|X)=\frac{1}{Z(X)}\tilde{P}(Y,X)&lt;/equation&gt;&lt;equation&gt;\tilde{P}(Y,X)=exp(\sum_i w_i * f_i(Y,X))&lt;/equation&gt;&lt;equation&gt;Z(X)=\sum_Y exp(\sum_i w_i * f_i(Y,X))&lt;/equation&gt;&lt;p&gt;可以看出，条件随机场在建模的时候同样需要计算联合概率，只不过这一次参与计算的有两部分随机变量——X和Y。一般来说，我们把X称作观察变量，也就是已知的变量；Y称作目标变量或者隐含变量，是我们想知道的变量。&lt;/p&gt;&lt;p&gt;比方说图像分割的问题，X就是图像的像素，Y就是每个像素所归属的类别。当然对于二维的图像问题还是有点复杂，那么我们用一个简单的一维问题做了例子：比方说自然语言处理中的词性标注问题，那么它的建模形式如下所示：&lt;/p&gt;&lt;equation&gt;\tilde{P}(Y,X)=exp(\sum_i f_1(X_i,Y_i) + f_2(Y_i,Y_{i+1}))&lt;/equation&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;如果你在读这篇文章之前并不了解CRF，那么我相信这篇文章并不能让你对CRF有很深的印象，但是多多少少会有点了解。总体来说，采用无向图模型建模的CRF具有很强的灵活性和适应性，但是计算起来却不那么容易。所有的inference必须从求解联合概率入手，而且还要计算normalization那一项。所以计算是无向图模型的难题，后面我们也会深入计算这个问题，试图解决难以计算这个问题。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464581&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 03 Nov 2016 23:12:56 GMT</pubDate></item><item><title>FCN(1)——从分类问题出发</title><link>https://zhuanlan.zhihu.com/p/22464571</link><description>前面我们介绍了许多利用CNN进行分类任务的模型，今天我们来看看用CNN做分割的模型。我们的主要内容来自这篇文章——《Fully Convolutional Networks for Semantic Segmentation》。&lt;h2&gt;图像分割&lt;/h2&gt;&lt;p&gt;首先我们来简单看看图像分割的任务是什么样的。所谓的图像分割就是将一幅图像中各个实体的边界确定下来，这样我们可以通过寻找这个实体的边界确定实体的位置。在自然场景中我们可以根据画面中的实体进行划分，在文档图片中，我们也可以找出每一个文字的边界。这些都可以算作是完成分割任务。&lt;/p&gt;&lt;p&gt;当然，上面的描述还不太具有可操作性，我们可以把问题做进一步地转化。我们可以把问题转换成一个分类问题，我们判定每一个像素点的类别，然后将相邻且类别相同的像素点聚集起来，不就可以找到实体的边界了么？这样也就是从分类问题出发解决分割问题的方式。&lt;/p&gt;&lt;p&gt;但是这样解决分割问题的方法还是存在一些问题：之前我们对于一张图像，最终只输出一个结果或者几个结果，结果的数量并不多；而现在我们输出的数量和像素的数量相同，那么我们还能够获得和分类问题近似的精确率么？这里面存在着一些需要解决的问题，比如：&lt;/p&gt;&lt;p&gt;在分类问题中，为了解决图像的transform invariance，我们会加入pooling层减小维度，这个被减小的纬度如何能够再次放大呢？&lt;/p&gt;&lt;h2&gt;FCN的解决方案&lt;/h2&gt;&lt;p&gt;FCN，也就是Fully Convolutional Network，是一个不包含全连接层的网络。这里面所谓的不包含全连接层，实际上并不是标榜自己没有全连接层，而是为了保证计算过程中每一层数字的相对位置。在我们通常的印象中，全连接层需要把本来立体的图像拍平，这样原本存在的空间特性将被抹掉。为了确保我们识别出来的类别能和原来每一个像素点的位置对上，我们不能粗暴地把中间数据拍平，这也是网络中不使用全连接层的原因。&lt;/p&gt;&lt;p&gt;我们可以利用常规的分类CNN网络得到一个接近最终结果的中间层，这样层的数据往往已经可以代表了一些具有特定含义的特征，而不再像原始的像素亮度那样含义晦涩。因此我们可以从这样的信息出发得到一些分类信息，然后把这些分类信息重新映射到原始图片大小的区域上。&lt;/p&gt;&lt;p&gt;由于中间层的维度比原始图像小，那么恢复到原始大小必然意味着一些插值的工作。一旦使用了插值的算法（比方说bilinear），那么恢复的图像的精度一定会出现问题。所以大神们也曾经担心过这个问题。于是他们也想出过一些其他的方法。这些方法的特点就一条——&lt;/p&gt;&lt;p&gt;维度不缩小！&lt;/p&gt;&lt;p&gt;实际上想做到这一步从算法上来说也并不困难，但是这样的方法会增加不少计算量，而且也存在自己的问题。最终大神们选择了反卷积的方式完成了信息由小变大的工作。&lt;/p&gt;&lt;p&gt;反卷积可以让维度由小变大，而且我们还可以通过学习其中的参数让这个变化的过程变得不那么简单粗暴。但是小维度毕竟是小维度，谁也没法回避这个问题。就算采用反卷积的方式把维度扩大，精度损失的问题依旧无法避免。所以我们还需要其他的办法。&lt;/p&gt;&lt;p&gt;这个办法就是融合。我们不仅仅使用较深层的特征信息，还使用一些较浅的特征信息。我们知道较浅层的特征容易保留一些细节信息，比方说边缘信息，较深的特征容易保留一些类别信息，那么如果我们把这两部分信息融合起来，我们既可以保证找到的类别信息是准确的，同时我们也可以保证一些边缘的位置信息能够找准。这样我们也就解决了这个问题。&lt;/p&gt;&lt;p&gt;文章中还提到了一个有意思的问题，那就是采样的问题。一般来说我们的分类问题都是一张图一套类别信息，而现在的分割问题变成了一张图有许许多多的类别信息。这么多类别信息一起学习，会不会出现过拟合的问题？最终的实验结果告诉了我们，过拟合的问题似乎并不存在，但是当初大家还是担心了一下，也曾经想过采用采样的方式解决这个问题。对于最终输出的每一个像素的类别信息，我们并不把所有的像素点的结果计算到loss中进行反向传播，而是只取其中一部分的像素点。这个想法是有点道理的，因为每一个紧密相邻的像素点之前的特征差距可能并不大，如果每一个像素点都计算在内，那么就相当于我们对某一组特征增加了很高的权重。但好在我们对所有像素点都增加权重的话，这个影响还是会抵消的。&lt;/p&gt;&lt;p&gt;最后提一下分割问题和分类问题在evaluation方面的不同。对于经典的分类问题，我们常用的loss是cross entropy loss，精确率判断则是最终的类别判断的正确率。而在分割问题中，我们除了判断每一个像素点的“分类”loss和精确率，我们还可以计算IoU。它的全称是Intersection of Union。我们有模型预测的边界和Ground Truth的边界。我们计算两个边界相交和它们相并的比例，也可以判断最终的分割效果。如果以IOU作为评价标准，那么只要主体部分能够分割正确，那么我们就可以拿到比较高的分数。所以添加过多浅层的信息可能不会对最终结果造成很大的准确率提升。&lt;/p&gt;&lt;h2&gt;未来&lt;/h2&gt;&lt;p&gt;从上面的内容中，我们基本上完成了对FCN的基本介绍。FCN是一个将High-level问题的模型框架应用到Low-level问题的成功案例。但是，从已经走过的历史长河来看，这个方法开辟一片崭新的领域，但是并没有走在这个领域的前沿。所以相关的应用在此我们也不赘述了，留给大家自己开发了。&lt;/p&gt;&lt;p&gt;曾经在图像分割问题中，我们经常使用概率图模型的方式进行建模求解，正如一些童鞋所知。后来的大神们尝试了深度CNN和CRF模型结合的手段进行尝试，并获得了非常不错的成绩。在后面的篇幅里我们就来看看两种方法是如何结合在一起的。&lt;/p&gt;&lt;p&gt;当然，我们花了很长的时间介绍了CNN模型的方方面面，所以一路看下来的各位对CNN已经比较熟悉，所谓没吃过猪肉也见过猪跑了。但是CRF的内容在此之前我们并未涉及到，因此想搞清楚CRF对于初学者还是有点压力，下面我们会尽可能地用最通俗的语言介绍下CRF。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"5群已经准确就绪：583914960，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;583914960！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464571&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Sun, 30 Oct 2016 21:03:29 GMT</pubDate></item><item><title>Caffe中的SGD的变种优化算法(2)</title><link>https://zhuanlan.zhihu.com/p/22464551</link><description>接上回，我们继续来看优化的算法。&lt;h2&gt;Adam&lt;/h2&gt;&lt;p&gt;关于adam的算法，我觉得它的复杂程度比前面的算法更高，但是它还是主要使用了和计算动量相同的方法，并把这种方法应用到梯度的一阶总量和二阶总量上：&lt;/p&gt;&lt;equation&gt;m_{t+1} = \beta_1 * m_t+(1-\beta_1)*g&lt;/equation&gt;&lt;equation&gt;v_{t+1}=\beta_2*v_t+(1-\beta_2)*g^2&lt;/equation&gt;&lt;p&gt;同时作者发现这两个变量存在某种偏差，于是又给这两个变量加上了一定的修正量：&lt;/p&gt;&lt;equation&gt;\hat{m_t}=\frac{m_t}{1-\beta_1^t}&lt;/equation&gt;&lt;equation&gt;\hat{v_t}=\frac{v_t}{1 - \beta_2^t}&lt;/equation&gt;&lt;p&gt;最后我们将这两个变量融合起来得到最终的更新公式：&lt;/p&gt;&lt;equation&gt;x_{t+1}= x_t - lr*\frac{\hat{m_t}}{\sqrt{\hat{v_t}} + \varepsilon }*g_t&lt;/equation&gt;&lt;p&gt;它的代码如下所示：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;def adam(x_start, step, g, beta1 = 0.9, beta2 = 0.999,delta=1e-8):
    x = np.array(x_start, dtype='float64')
    sum_m = np.zeros_like(x)
    sum_v = np.zeros_like(x)
    passing_dot = [x.copy()]
    for i in range(50):
        grad = g(x)
        sum_m = beta1 * sum_m + (1 - beta1) * grad
        sum_v = beta2 * sum_v + (1 - beta2) * grad * grad
        correction = np.sqrt(1 - beta2 ** i) / (1 - beta1 ** i)
        x -= step * sum_m / (np.sqrt(sum_v + delta))
        passing_dot.append(x.copy())
        if abs(sum(grad)) &amp;lt; 1e-6:
            break;
    return x, passing_dot
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;前面也说过，实际上这些算法背后都有些原理的，但是这些原理在我们看来可能都比较抽象，所以再我们看完实验再看原理可能会更有感觉。下面我们看看它的表现：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = adam([5, 5], 0.1, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5dd1a9d087cd51deb2bd426bc7f7eeb6.png" data-rawwidth="878" data-rawheight="420"&gt;好吧，这一回它是唯一一个走得有点过头的算法，不过最后还是走上了正道。&lt;/p&gt;&lt;p&gt;这样除了Nesterov算法之外，我们把其他所有的算法都展示出来了。前面这个实验中，我们希望检验算法的“拐弯”能力。也就是说一开始算法冲着一个局部最优点而来，什么时候它会发现这是个骗局并掉头朝向真正的最优值呢？现在每一个算法都给我们交出了答案。仔细看来每个算法的表示还是不太一样的。有的算法比较灵敏，刚发现不对就调头逃跑，有的算法则是冲过了头才转过身来。有的算法做到这一切十分容易，并不需要很大的Learning rate，有的算法则需要强大的力量才能转过来，否则就会行动缓慢。&lt;/p&gt;&lt;p&gt;好了，各位童鞋，转弯赛到此结束，下面我们进入下一个比赛——爬坡赛。爬坡赛的比赛规则是，所有算法使用同样的参数，从鞍点附近出发，经过50轮迭代，看看它能走到哪里。&lt;/p&gt;&lt;h2&gt;爬坡赛&lt;/h2&gt;&lt;p&gt;首先是我们的老朋友梯度下降法：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = gd([-0.23,0.0], 0.0008, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1801c65667491bcfb980ab62cf2501ec.png" data-rawwidth="872" data-rawheight="424"&gt;我们的老朋友在爬坡赛看来是要叫白卷了，说明它虽然很轻盈，但是动力不是很足啊。&lt;/p&gt;&lt;p&gt;下面是动量算法：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = momentum([-0.23,0], 5e-4, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-0a8e5a430e33f21cd6a79334a496130e.png" data-rawwidth="888" data-rawheight="423"&gt;比梯度下降好一点，但是好的有限。&lt;/p&gt;&lt;p&gt;然后是Adagrad：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = adagrad([-0.23, 0], 1.3, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-63aaf5fdc0c324ca90369c0dad1ab46b.png" data-rawwidth="894" data-rawheight="425"&gt;好吧，表现得比转弯赛还好，省去夸赞的词语了。&lt;/p&gt;&lt;p&gt;下面是Rmsprop:&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = rmsprop([-0.23, 0], 0.3, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-59f403485d1ef7a948e3bd37a5b01799.png" data-rawwidth="879" data-rawheight="425"&gt;同样完成的不错！&lt;/p&gt;&lt;p&gt;下面我们再看AdaDelta：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = adadelta([-0.23, 0], 0.4, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-c59bcdecca66aeaf2e68f46876a2ddfb.png" data-rawwidth="884" data-rawheight="418"&gt;好吧，直接一骑绝尘而去了。&lt;/p&gt;&lt;p&gt;最后是我们今天登场的Adam：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;res, x_arr = adam([-0.23, 0], 0.1, g)
contour(X,Y,Z, x_arr)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-ea60a426346859e020dafd83cb3a311e.png" data-rawwidth="882" data-rawheight="422"&gt;同样是跑出了我们原始规划的区域。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;经过两轮的比赛——转弯赛和爬坡赛，我们测试了几种算法在同一配置上的实力。测试的目标不是为了比较哪个算法更厉害，而是展示另外一个实力——哪个算法表现更稳定。&lt;/p&gt;&lt;p&gt;因为我们在实际使用过程中，learning rate是相对固定的，在优化过程中我们无法预料自己将会碰上什么样的情景，那么我们肯定希望一个算法又能转弯又能爬坡。如果一个算法转弯厉害但是爬坡比较弱，那一旦遇上爬坡它就会走得很慢，反之也是如此。&lt;/p&gt;&lt;p&gt;所以从刚才的表现来看，我们的新算法似乎表现更为平稳，现在也确实有越来越多的人抛弃了一些经典的算法，转而投入这些新算法的怀抱，而这些新算法也足够争气，拿出了它们的实力。关于算法性能的测试一直在进行，这些算法还需要经历更多的考验！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464551&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Wed, 26 Oct 2016 22:06:55 GMT</pubDate></item></channel></rss>