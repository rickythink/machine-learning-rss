<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>机器之心年度盘点 | 从技术角度，回顾2016年语音识别的发展</title>
      <link>http://www.iwgc.cn/link/4067617</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;得益于深度学习与人工神经网络的发展，语音识别在2016年取得了一系列突破性的进展，在产品应用上也越来越成熟。作为语音交互领域中极其重要的一环，语音识别一直是科技巨头研究的重点，国内外也涌现出了一批优秀的创业公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6QCE8x2TY4nVc5lghOw2ibtP8oC4hA9xAGQmJx4ibvnWgfjZRXuudpicJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年年初，机器之心发布来自 ACM 中文版的文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401894776&amp;amp;idx=1&amp;amp;sn=e963169d912f307104b97e0d7cd03cb7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401894776&amp;amp;idx=1&amp;amp;sn=e963169d912f307104b97e0d7cd03cb7&amp;amp;scene=21#wechat_redirect"&gt;深度 | 四十年的难题与荣耀——从历史视角看语音识别发展&lt;/a&gt;》，文中微软首席语音科学家黄学东为我们深入解读了语音识别的历史以及发展难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长久以来，人与机器交谈一直是人机交互领域内的一个梦想。语音识别做为很基础的技术在这一年中再次有了更大的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一年中，机器之心拜访过科大讯飞，接触过云知声、思必驰等创业公司，在微软的英语语音识别取得突破后更是深度专访了微软的黄学东、俞栋，不久之前的百度语音开发平台三周年的主题活动上我们也向百度首席科学家吴恩达了解过百度的语音识别发展。我们希望从机器之心文章中梳理出的线索，能为接下来语音识别的发展提供一丝洞见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们会依次梳理 2016 年机器之心关注到的语音识别领域的突破性研究、未来待解决的难题、语音识别发展历史中较为重要的时间点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、2016 年语音识别有哪些突破？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分盘点了 2016 年机器之心所关注到的在语音识别准确率上取得的突破，主要涉及的公司包括百度、IBM 和微软等。根据这些突破，我们梳理出了一条语音识别技术发展的线路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=2&amp;amp;sn=3308e3bcea1cdeb2eaee13c241081ad6&amp;amp;chksm=871b0c63b06c85751f06672a9d714f1b414f959e9129120d5d00532b72adeaf7cb9577a0989b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=2&amp;amp;sn=3308e3bcea1cdeb2eaee13c241081ad6&amp;amp;chksm=871b0c63b06c85751f06672a9d714f1b414f959e9129120d5d00532b72adeaf7cb9577a0989b&amp;amp;scene=21#wechat_redirect"&gt;百度 Deep Speech 2 的短语识别的词错率降到了 3.7%&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发生时间：2016 年 2 月&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Speech 2 于 2015 年 12 月首次发布时，首席科学家吴恩达表示其识别的精度已经超越了 Google Speech API、wit.ai、微软的 Bing Speech 和苹果的 Dictation 至少 10 个百分点。到今年 2 月份时，Deep Speech 2 的短语识别的词错率已经降到了 3.7%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久之前，百度又将 Deep CNN 应用于语音识别研究，使用了 VGGNet，以及包含 Residual 连接的深层 CNN 等结构，并将 LSTM 和 CTC 的端对端语音识别技术相结合，使得识别错误率相对下降了 10%（原错误率的 90%）以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据百度语音技术部识别技术负责人、Deep Speech 中文研发负责人李先刚博士介绍说，百度正在努力推进 Deep Speech 3，这项研究不排除将会是 Deep Speech 3 的核心组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术提升基础：1. 端到端深度学习方法；2. 深层卷积神经网络技术（Deep CNN）应用于语音识别声学建模中，与基于长短时记忆单元（LSTM）和连接时序分类（CTC）的端对端语音识别技术相结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=4&amp;amp;sn=4555a0f8732224da7055e120a3f9112f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=4&amp;amp;sn=4555a0f8732224da7055e120a3f9112f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2.IBM Watson 会话词错率低至 6.9%&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发生时间：2016 年 5 月&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年，IBM Watson 公布了英语会话语音识别领域的一个重大里程碑：系统在非常流行的评测基准 Switchboard 数据库中取得了 8% 的词错率（WER）。到了今年 5 月份，IBM Watson 团队再次宣布在同样的任务中他们的系统创造了 6.9% 的词错率新纪录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术提升基础：声学和语言建模两方面技术的提高&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;微软新系统英语语音识别词错率低至 6.3%&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发生时间：2016 年 9 月&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在产业标准 Switchboard 语音识别任务上，微软研究者取得了产业中最低的 6.3% 的词错率（WER）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术提升基础：基于神经网络的声学和语言模型的发展，数个声学模型的结合，把 ResNet 用到语音识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;微软英语语音识别词错率达到了 5.9%，媲美人类&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发生时间：2016 年 10 月&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软人工智能与研究部门的团队报告出他们的语音识别系统实现了和专业速录员相当甚至更低的词错率（WER），达到了 5.9%。5.9% 的词错率已经等同于人速记同样一段对话的水平，而且这是目前行业标准 Switchboard 语音识别任务中的最低记录。这个里程碑意味着，一台计算机在识别对话中的词上第一次能和人类做得一样好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术提升基础：系统性地使用了卷积和 LSTM 神经网络，并结合了一个全新的空间平滑方法（spatial smoothing method）和 lattice-free MMI 声学训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然在准确率的突破上都给出了数字基准，但百度与微软、IBM（switchboard 上测试）有较大的不同。微软的研究更加学术，是在标准数据库——口语数据库 switchboard 上面完成的，这个数据库只有 2000 小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软研究院的研究关注点是基于 switchboard 数据库，语音识别最终能做到什么样的性能。而据百度语音识别技术负责人李先刚介绍，他们的关注点是语音技术能够深入到大家的日常应用中，他们用的数据长达数万小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄学东在之前接受机器之心专访时也表示他们的这个语音识别系统里面没有 bug，因为要在标准数据上做到这样的水平，实际上体现了工程的完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就各项突破的技术提升基础，我们可以很明晰的梳理出一条线：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 之前 LSTM 这样的模型开始成功应用于语音识别，今年的后续研究不断提升 LSTM 的模型效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 另外一个比较大的进展是 Deep CNN。Deep CNN 比起双向 LSTM（双向效果比较好）有一个好处——时延。所以在实时系统里会更倾向于用 Deep CNN 而不是双向 LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 端到端学习，这也是百度首席科学家吴恩达在 NIPS 2016 上重点提到的。比如语音识别，输入的是语音，输出的是文本，这是比较纯粹的端对端学习。但是它也有缺点——需要足够大的训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6akBDyVmB7nKrUQT75RTHEPiaLYxxh58MwNo1G60Uia9rRcK0ic7uvpQXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：吴恩达 NIPS 2016 ppt&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这方面现在的研究工作主要集中在两类模型上。一类就是 CTC 模型，包括 Johns Hopkins 大学的 Dan Povey 博士从 CTC 发展出来的 lattice-free MMI；还有一类是基于注意的序列到序列模型。今天它们的表现也还是比混合模型逊色，训练的稳定性也更差，但是这些模型有比较大的潜力（参考机器之心对俞栋老师的专访）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;国内还有其他几家做语音识别的公司，这里对科大讯飞、搜狗、云知声的语音识别系统做个简单介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年年底，科大讯飞提出了以前馈型序列记忆网络（FSMN, Feed-forward Sequential Memory Network）为代表的新一代语音识别系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年，科大讯飞又推出了全新的深度全序列卷积神经网络（Deep Fully Convolutional Neural Network, DFCNN）语音识别框架，使用大量的卷积层直接对整句语音信号进行建模，更好的表达了语音的长时相关性。据介绍，该框架的表现比学术界和工业界最好的双向 RNN 语音识别系统识别率提升了 15% 以上。其结构图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6mcI197HatX1ZiaFhhPJLXT2qVUS252FDPygYtGAibrIaoSiauw9sibI5sg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;科大讯飞 DFCNN 的结构图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，我也附上搜狗、云知声提供的各自的语音识别系统的流程，以供大家学习、比较、参考：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6RJnIPibw0pGnl1hVibzx3CqKWpqtKv5RgOOM0tXzrjicvlfTvcFP1dd2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;语音识别系统流程：语音信号经过前端信号处理、端点检测等处理后，逐帧提取语音特征，传统的特征类型包括 MFCC、PLP、FBANK 等特征，提取好的特征送至解码器，在声学模型、语言模型以及发音词典的共同指导下，找到最为匹配的词序列作为识别结果输出。&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6EkZmUgf7ia0Su3RWibvHRmGYTeCbH9gubU8U6fIbPu7pL5ibYus93AetA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗 CNN 语音识别系统建模流程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6Yt9qwlFDRZKbVNhlBMxxhlWm88qxyic39z7atJWXjLdCyaJ6rKrlvcg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云知声语音识别系统&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、难题与前沿方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在语音识别高速发展的一年，我们曾专访过黄学东、俞栋等多位领域内的专家，不可避免的探讨了未来语音识别领域所面临的方向、挑战、抑或是难题。现如今整理如下，希望能对大家接下来的语音识别研究有所帮助：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 语义理解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄学东认为，要做好语音识别需要更好的语义理解，二者相辅相成。「人的鲁棒性非常好，一个新的课题过来，他可以通过会话的方式跟你沟通，也能得到很好的结果。而机器对噪音的抗噪性不够强，对新的课题会话沟通能力比较差。最重要的一点是，语音识别并没有理解你的语义。理解语义是人工智能下一个需要攻克的难题，这也是我们团队花很多时间和精力正在做的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 值得关注的四大方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之前机器之心对俞栋的专访中，他为我们指出了语音识别领域的几大前沿：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在安静环境下并使用近距麦克风的场合，语音识别的识别率已越过了实用的门槛；但是在某些场景下效果还不是那么好，这就是我们这个领域的 frontier。现在大家主攻几点：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;首先，是不是能够进一步提升在远场识别尤其是有人声干扰情况下的识别率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前一般远场识别的错误率是近场识别错误率的两倍左右，所以在很多情况下语音识别系统还不尽如人意。远场识别至少目前还不能单靠后端的模型加强来解决。现在大家的研究集中在结合多通道信号处理（例如麦克风阵列）和后端处理从拾音源头到识别系统全程优化来增强整个系统的表现。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;另外，大家还在研究更好的识别算法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这个「更好」有几个方面：一个方面是能不能更简单。&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;现在的模型训练过程还是比较复杂的&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;，需要经过很多步骤。如果没有 HTK 和 Kaldi 这样的开源软件和 recipe 的话，很多团队都要用很长时间才能搭建一个还 OK 的系统，即使 DNN 的使用已经大幅降低了门槛。现在因为有了开源软件和 recipe，包括像 CNTK 这样的深度学习工具包，事情已经容易多了，但还有继续简化的空间。这方面有很多的工作正在做，包括如何才能不需要 alignment 、或者不需要 dictionary。现在的研究主要还是基于 end-to-end 的方法，就是把中间的一些以前需要人工做的步骤或者需要预处理的部分去掉。虽然目前效果还不能超越传统的 hybrid system，但是已经接近 hybrid system 的 performance 了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;另外一个方面，最近的几年里大家已经从一开始使用简单的 DNN 发展到了后来相对复杂的 LSTM 和 Deep CNN 这样的模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;但在很多情况下这些模型表现得还不够好。所以一个研究方向是寻找一些特殊的网络结构能够把我们想要 model 的那些东西都放在里面。我们之前做过一些尝试，比如说人在跟另外一个人对话的过程中，他会一直做 prediction，这个 prediction 包括很多东西，不单是包括你下一句想要说什么话，还包括根据你的口音来判断你下面说的话会是怎样等等。我们曾尝试把这些现象建在模型里以期提升识别性能。很多的研究人员也在往这个方向走。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;还有一个方向是快速自适应的方法—就是快速的不需要人工干预的自适应方法（unsupervised adaptation）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;现在虽然已经有一些自适应的算法了，但是它们相对来说自适应的速度比较慢，或者需要较多的数据。有没有办法做到更快的自适应？就好像第一次跟一个口音很重的人说话的时候，你可能开始听不懂，但两三句话后你就可以听懂了。大家也在寻找像这种非常快还能够保证良好性能的自适应方法。快速自适应从实用的角度来讲还是蛮重要的。因为自适应确实在很多情况下能够提升识别率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、语音识别历史的梳理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一部分我简单的梳理了一下语音识别历史上比较关键的一些时间点，至于详细的语音识别技术研究历史可参考之前提到的黄学东老师写的《四十年的难题与荣耀——从历史视角看语音识别发展》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1952 年，贝尔实验室 Davis 等人研制了世界上第一个能识别 10 个英文数字发音的实验系统，但只能识别一人的发音。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1962 年，IBM 展示了 Shoebox。Shoebox 能理解 16 个口语单词以及 0-9 的英文数字。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1969 年，贝尔实验室的 John Pierce 预言成熟的语音识别在数十年内不会成为现实，因为它需要人工智能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1970 年，普林斯顿大学的 Lenny Baum 发明隐马尔可夫模型（Hidden Markov Model)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;20 世纪 70 年代，卡耐基梅隆大学研发 harpy speech recognition system，能够识别 1011 个单词，相当于 3 岁儿童的词汇量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;20 世纪 80 年代，语音识别引入了隐马尔可夫模型（Hidden Markov Model)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;20 世纪 90 年代出现首个消费级产品 DragonDictate，由国际语音识别公司 Nuance 发布。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2007 年，Dag Kittlaus 和 Adam Cheyer 创立 Siri.Inc。后被苹果收购并于 2011 年首次出现在 iPhone 4s 上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2009 年以来，借助机器学习领域深度学习研究的发展以及大数据语料的积累，语音识别技术得到突飞猛进的发展。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2011 年微软率先取得突破，使用深度神经网络模型之后，语音识别错误率降低 30%。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2015 年，IBM Watson 公布了英语会话语音识别领域的一个重大里程碑：系统在非常流行的评测基准 Switchboard 数据库中取得了 8% 的词错率（WER）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别，在这一年有了极大的发展，从算法到模型都有了质的变化，在加上语音领域（语音合成等）的其他研究，语音技术陆续进入工业、家庭机器人、通信、车载导航等各个领域中。当有一天，机器能够真正「理解」人类语言，并作出回应，那时我们必将迎来一个崭新的时代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;strong&gt;拓展阅读：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401894776&amp;amp;idx=1&amp;amp;sn=e963169d912f307104b97e0d7cd03cb7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401894776&amp;amp;idx=1&amp;amp;sn=e963169d912f307104b97e0d7cd03cb7&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | 四十年的难题与荣耀——从历史视角看语音识别发展&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 专访微软首席语音科学家黄学东： CNTK 是词错率仅 5.9% 背后的「秘密武器」&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;专访 | 顶级语音专家、MSR首席研究员俞栋：语音识别的四大前沿研究&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=2&amp;amp;sn=3308e3bcea1cdeb2eaee13c241081ad6&amp;amp;chksm=871b0c63b06c85751f06672a9d714f1b414f959e9129120d5d00532b72adeaf7cb9577a0989b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=2&amp;amp;sn=3308e3bcea1cdeb2eaee13c241081ad6&amp;amp;chksm=871b0c63b06c85751f06672a9d714f1b414f959e9129120d5d00532b72adeaf7cb9577a0989b&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;专访｜百度语音识别技术负责人李先刚：如何利用Deep CNN大幅提升识别准确率？&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;重磅 | 语音识别新里程碑：微软新系统词错率低至6.3%（附论文）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;重磅 | 微软语音识别实现历史性突破：语音转录达到专业速录员水平（附论文）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=4&amp;amp;sn=4555a0f8732224da7055e120a3f9112f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=4&amp;amp;sn=4555a0f8732224da7055e120a3f9112f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;公司｜IBM Watson 团队取得语音识别新突破，会话词错率低至 6.9%&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=1&amp;amp;sn=da2e46b031173adc25d16a68e2fcb54b&amp;amp;chksm=871b034cb06c8a5a1984b1158e83e94095ce12aff6fd0fe42126429e6e942aa786714c904589&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=1&amp;amp;sn=da2e46b031173adc25d16a68e2fcb54b&amp;amp;chksm=871b034cb06c8a5a1984b1158e83e94095ce12aff6fd0fe42126429e6e942aa786714c904589&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | 在语音识别这件事上，汉语比英语早一年超越人类水平（附论文）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=4&amp;amp;sn=05badbcd6230247e75b57e3df6a8e131&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=4&amp;amp;sn=05badbcd6230247e75b57e3df6a8e131&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | 语音识别软件太傻？斯坦福研究表明语音输入比打字快三倍、准确率更高&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 26 Dec 2016 13:09:18 +0800</pubDate>
    </item>
    <item>
      <title>公告 | 对不起，机器之心在连续更新1000天之后……</title>
      <link>http://www.iwgc.cn/link/4054023</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibxl4MIXv3L6R8wYrSb79dxoW3J0J0sXTShnJBic9rbRfbfzOnqm5WBoQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibLh15sJ4GZH0kaTkTfDFqia0EMvmFI2chkdnoEVyYHr2y2iaupEHBZicpw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 25 Dec 2016 00:04:33 +0800</pubDate>
    </item>
    <item>
      <title>重磅论文 | 机器学习硬件概览：从算法到架构的挑战与机遇</title>
      <link>http://www.iwgc.cn/link/4048022</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，MIT 发表一篇论文，从架构（GPU、CPU、FPGA）到算法概述机器学习硬件研究中的机遇与挑战。在人工智能硬件火热的今天，这是一篇不可错过的综述性文章。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juib8OmczjKp1TY6lGmBgB6m3V9p1qBBNQic7GM6Gbvia803ElrlpqRiaTDaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：机器学习在从传感器每天收集的大量数据中提取有用信息上发挥着非常重要的作用。在一些应用上，目的是为了分析并理解数据，从而辨清发展趋势（例如，监控、便携式／穿戴式电子设备）。在其他应用中，分析数据的目的是为了能够基于数据快速作出应对（例如，机器人/无人机、自动驾驶汽车、物联网）。对这些应用而言，出于对隐私、安全的考虑，再加上通信带宽的限制，在传感器附近的本地嵌入式处理要比上传到云更好。然而，在传感器端的处理有能耗与成本的限制，还有生产能力与准确率的要求。此外，也需要适应性，以便于传感器适应于不同的应用或环境（例如，在分类器上升级权重与模型）。在许多应用中，机器学习总是涉及到将输入数据转换到更高维度的空间，这伴随着可编程权重、增加数据传输以及最终的能量消耗方面的问题。在此论文中，我们将探讨如何在各种级别的硬件设计上解决这些问题：架构、硬件友好的算法、混合信号线路和高级技术（包括内存与传感器）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、 导语&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在是大数据时代。过去两年创造的数据要多于人类历史上所创造的所有数据。这主要是由于传感器（2013 年平均为 100 亿个，预期到 2020 年达到 1 万亿个）和连接设备（2016 年为 64 亿个，预期在 2020 年达到 208 亿个）的使用。这些传感器和设备每年生成数百泽字节（zatabyte）的数据，每秒生成拍字节（petabyte）的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要机器学习从这些数据中提取有用的、可理想地实施的信息。分析数据所需的大量数据分析经常是在云中做的。然而，在数据生成量与生成速度如此大的情况下，再加上通信的高能耗和宽带的限制，在传感器附近本地完成分析的需求越来越大，而非将原始数据发送到云中。在这些边缘地带嵌入机器学习也解决了对隐私、潜在安全性的担忧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、应用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从多媒体到医疗领域（medical space），许多应用都能从嵌入机器学习中受益。我们会提供几个研究领域的样本；不过，这篇论文主要关注的是计算机视觉，特别是图像分类，作为推进案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibz0wSvfKfZUNKicBAWMErZynLuvJEhkfKSl4ZRslvRm8v7gCnun7DY2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：图像分类&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A.计算机视觉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频可能是最大的大数据。约占今天互联网流量的 70%。比如，全世界每天收集起来、需要审查的视频达 8 亿小时。在许多应用（比如，测量商店、交通模式下的等待时间）中，使用计算机视觉从图像传感器上（而不是云端）的视频中提取有意义的信息是极好的，能减少通信成本。就其他一些应用（比如自动驾驶车辆、无人机导航和机器人技术）来说，会需要本地化处理，因为依赖云端会有很大安全风险，还会有延迟的问题。不过，视频包括大量数据，处理起来，计算会很复杂，因此，分析视频的低成本硬件就成了让这些应用得以实现的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算机视觉方面，有许多不同的人工智能任务。本文聚焦图像分类（如表一所示），有图像，任务就是判定图像目标类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;B. 语音识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别显著改善了人类与设备的互动，比如智能手机。尽管目前绝大多数应用程序，比如苹果 Siri 和亚马逊的 Alexa 语音服务的处理位于云端，但是，在设备上面执行识别任务更理想，因为可以减少延迟和对连接的依赖，并且能增强隐私。语音识别是实现机器翻译、自然语言处理等很多其他人工智能任务的第一步。人们在研究用于语音识别的低功率硬件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;C. 医学&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;临床医学非常看重对病人的监测，收集长期数据帮助侦测/诊断各种疾病或者监督治疗。比如，持续的 ECG 或 EEG 信号监测将有助于识别心血管疾病，检测癫痫患者的发作。在许多情况下，这些设备要么是穿戴式的，要么是可移植的，因此，能耗必须维持在最低。所以，需要探索使用嵌入机器学习提取有意义的生理信号进行本地化处理的办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、机器学习基础&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个典型机器学习的推论流程可以分为两步（如图 2）：特征提取和分类。有些方法，比如深度神经网络（DNN）就模糊了步骤之间的差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibZL256jZDhzMZxYPSX2BlSS7Q00bQ6nOQJ3VO4l2T47HSZp20VsHWqA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：推理流程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A. 特征提取&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征提取是将原始数据转化为对给定任务有意义的输入。传统意义上，特征提取是通过该领域的专家手工进行标注而设计的。例如，计算机视觉中的对象识别就是根据观察到人类视觉是对图像边缘（如梯度）具有敏感性而设计的。因此，许多众所周知的计算机视觉算法 Histogram of Oriented Gradients (HOG) 和 Scale Invariant Feature Transform (SIFT) 使用的就是基于图像梯度的特征。设计这些特征的挑战就是保证他们在过曝或噪点的情况下保持鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;B. 分类算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征提取的输出由向量表示，并且用分类器将这个过程映射到一个得分上。根据应用，分类权重可以和阀值比较来决定对象是否是当前的，或者也可以和其他得分相比较决定对象的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类算法技术上通常使用支持向量机（SVM）和 Softmax 回归等线性方法，还有核函数支持向量机（kernel-SVM）和 Adaboost 等非线性方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;C. 深度神经网络（DNN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络不需要使用手工标注的特征，它能从数据中直接学习到这些特征，这一点和分类器中的权重分配很相似，这样整个系统就是从端到端训练。这种自动学习特征的方式在机器学习中很流行，我们称它为深度神经网络（DNN），也就是常说的深度学习。在很多任务上，深度神经网络通过将输入数据映射到高维空间，这种方式在很多任务上实现的精度要比手工提取的特征精确得多，然而，代价就是高度计算复杂性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现存有许多深度神经网络架构（如卷积神经网络和循环神经网络等）。对于计算机视觉的应用，深度神经网络由多个卷积层（CONV）组成（如图 3）。每层将输入数据抽象到更高一层，称之为特征映射，这种更高层的抽象被提取以保留重要而独特的信息。现代深度神经网络能通过采用非常深的层级来实现优越的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibs4y9UkrpP2xwIel94icPbvMMCvuibwKMnCxnN7nHQxHYmzjSrVLqr9SA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：深度神经网络由多个卷积层组成，后面跟着全连接层&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibibpPZN7zWkQwyDYNichx9dI7KH9GlfseJhnbMmByG3rdlXdEYkZgKoTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图.4 DNN 中某个卷积的计算&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 1 比较了现代深度神经网络和 20 世纪 90 年代流行的神经网络的层级数（深度）、滤波器的权重数量、操作数量（如 MACs）。如今的深度神经网络在计算和储存上都领先几个数量级&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibArRqJajEpKZib5Z5jdfYvweaLNCvQZ6hVogsuc3eyqPK3scxdoRVw8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1：流行的 CNN 的总结 [21, 22, 25, 27, 28]. 基于 ImageNet top-5error 的精度测量 [19]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;D. 任务的复杂性 VS 难度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当比较不同的机器学习方法时，重要的是考虑任务的难度。例如，使用 MNIST 数据集进行手写数字分类的任务就比使用 ImageNet 数据集进行 1000 类物品分类简单得多。所以我们预期分类器或网络的大小（如权重数量）和 MACs 的数量在更难的任务中要多一些，也因此需要更多的能。例如，LeNet-5 被设计用来进行数字分类，而 AlexNet、VGG-16，GoogLeNet 和 ResNet 被设计用于进行 1000 类图像的分类任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;四、挑战&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;嵌入式机器学习的关键指标是精确度、能耗、吞吐量/延迟性以及成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习算法的精确性要在充足的大型数据组上进行测量。有许多广泛使用、公开使用的数据组可供研究人员使用（比如，ImageNet）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可编程性很重要，因为环境或应用变了后，权重也要更新。在 DNN 的案例中，处理器必须能够支持层数不同、滤波器以及通道大小不一的不同网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可编程性性的需求会增加数据计算和数据传送。更高的维度会增加生成的数据量，而且可编程性意味着需要读取并保存权重。这就对能效提出了挑战，因为数据传输要比计算更耗费成本。本文中，我们会讨论减少数据传输以最小化能耗的不同方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吞吐量取决于计算量，它也会随着数据维度的增加而增加。本文中，我们会讨论变换数据以减少所需操作数量的各种办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;成本在于芯片上所需的存储量。本文中，我们会讨论减少存储成本的各种办法，在芯片面积缩减的同时维持低芯片外存储带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，训练需要大量标签数据（特别是 DNNs）和计算（计算反向传播的多次迭代，判定权重值）。有人正在研究使用 CPU、GPU、 FPGA 和 ASIC 在云端进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，这超出了本文范围。目前，最先进的 DNNs 所耗费的能量比其他形式的嵌入处理（比如视频压缩）要高出几个数量级。我们必须利用多种硬件设计所带来的机遇，解决所有这些问题并减少能耗鸿沟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;五、 结构中的机遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuiboVvMNq45jSJMTM8wNXn780hUvUMTib2WGh3oXeHxAdwh5HeRVGMzR4A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：高度并行的计算范式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A. CPU 和 GPU 平台&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CPU 和 GPU 使用时间架构（比如 SIMD 或 SIMT）来并行执行 MAC。所有的 ALU 都共享同一个控制和存储（寄存器文件）。在这些平台上，所有的分类都由一个矩阵乘法表征。深度神经网络中的卷积层也能够用 Toeplitz 矩阵映射到一个矩阵乘法上。有专为 CPU 和 GPU 设计的软件库能用来优化矩阵乘法。该矩阵乘法按照更高层上的几兆字节的顺序平铺到这些平台的存储层次结构上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;B. 加速器（Accelerators）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加速器提供了优化数据传输（比如数据流）以最小化来自昂贵的分级存储器体系（如图 7）访问。特别是，对于 DNNs，我们调查了采用了三种数据再使用形式的数据流（卷积、滤波器和图像）。我们采用了一种空间结构（图 6），每个 ALU 处理元素（PE）带有本地存储（大约 0.5-1.0KB) 以及一个共享存储器（全局缓冲器），近 100-500KB。全局缓冲器与芯片外存储器（比如 DRAM）通讯。可以在使用了一个 NoC 的 PEs 之间进行数据传输，以减少对全局缓冲器以及芯片外存储器的访问。三种类型的数据传输包括输入像素、滤波器权重和部分和（即像素和权重的乘积），它们被累积起来用于输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibiao2cKRJnD7T5QklCNPMyhuv4JC049XeVnEjD21DvW4g9ibQqEliaa30Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 7. 分层级存储器和数据传输能耗&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期研究已经提出了一种 DNNs 加速方案，不过，很难直接比较因为实现和设计选择不同所导致的表现上的差异。图 8 可被用于分类现有的基于各自数据处理特征的 DNN 数据流：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibgBCDicxw20ZcsGTNib3iapicGSS4ABxcCfQrNZOGEGYEmLXPYBTOdMhzGg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8：DNNs 数据流&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;权重固定（Weight stationary，WS）：在该 PE 上，权重存储在 register file 中，并且保持平稳，以尽量减少权重移动成本（图.7(a)）。输入与局部和必须通过空间阵列和全局缓存。可看 [36-41] 中的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输出固定（Output stationary，OS）：在该 PE 上，输出存储在 register file 中，并且保持平稳，以尽量减少局部和的移动成本（图.7(b)）。输入与权重必须通过空间阵列和全局缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本地不重用（No local reuse,NLR）:从能量（(pJ/bit)）的角度看虽然小的 register file 有效率，但是从区域（(µm2 /bit)）来说，它们的效率就不高了。为了最大化存储功用，同时最小化片外存储器带宽，没有将本地存储分配给 PE，而是将所有区域分配给全局缓冲区以增加其容量（图.7(c)）。代价是会增加空间阵列上的流量及对于所有数据类型的全局缓冲。参见 [45-47] 中的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;行固定（Row stationary，RS）：为了增加所有类型数据（权重、像素、局部和）的 reuse，提出了一个行固定的方法 [35]。一行滤波器卷积保持固定在一个 PE 内，利用 PE 发掘 1-D 的 reuse。多个 1-D 行被结合在空间阵列上去彻底利用卷积 reuse（图.9），这会减少访问全局缓冲区。不同的信道和滤波器中的多个 1-D 的行被映射到每个 PE，以此来减少局部和数据传输并分别的利用过滤器 reuse。最后，跨阵列多通道允许额外的图像和过滤器 reuse 使用全局缓冲。这个数据流展示在 [48] 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juib90SnBxoRfddpDH5VsNjpS3DlBO7GHXibXXyPzlR42glTXgVvQfDEGJw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.9 行固定数据流&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具有相同数量的 PE（256）、区域成本（area cost）和深度神经网络（AlexNet）的空间阵列上比较数据流。图 10 展示了每种方法的能耗。行固定法（The row stationary approach）比其他卷积层数据流处理方法要节能 1.4 倍到 2.5 倍，这还是基于所有数据类型都更节能的事实上考虑的。此外，启动芯片和关闭芯片的能量也考虑了进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibRsO0NhVDxh5eJibiaNgJJgwvPjiblzGCMo7J1wvBybibAd98A2bDgLdNBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.10&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;六、算法与硬件联合设计中的机会&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在修改机器学习算法以使它们对硬件更友好同时还维持准确度方面，研究界一直有相关的研究工作；其中尤其值得关注的焦点是在减少计算量、数据传输和存储要求方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A 降低精度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CPU 和 GPU 等可编程平台的默认大小通常是 32 或 64 位的浮点数表示。尽管这仍然是训练方面的情况，但在推理过程中，使用定点数表示（fixed-point representation）是可能的，这可以减少位宽（bitwidth），从而降低能源消耗和设备尺寸，并且还能增加吞吐量。当把权重和特征推至更低的位宽时，为了保持准确度，通常还需要再训练（retraining）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工设计的方法中，位宽可以在不影响准确度的条件下大幅降低到 16 位以下。比如，在使用 HOG 的物体检测中，每 36 维特征向量仅需要每维度 9 位，而 SVM 的每个权重仅使用 4 位 [49]；对于使用可变形组件模型（DPM/deformable parts model）[55] 的物体检测而言，每个特征向量仅需要 11 位，每个 SVM 权重仅需要 5 位 [51]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地，对于 DNN 推理，加速器支持 16 位定点数是很常见的 [46,48]。在探索位宽对准确度的影响上有一些显著的研究工作 [52]。事实上，有报道称最新一款用于 DNN 的商业硬件支持 8 位整型运算 [53]。因为位宽可能会随层变化，研究者已经在探索使用这种位宽减少来实现硬件优化——相比于一个 16 位的定点的实现，他们得到了 2.56 倍的节能 [54] 或 2.24 倍的吞吐量增长 [55]。通过给网络进行更大的修改，有可能将权重 [56] 或权重及激活（activation）[57,58] 的位宽降低到 1 位，而在准确度上有所损失。硬件上 1 位权重的影响在 [59] 中有所探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;B 稀疏性（Sparsity）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 SVM 分类，其权重可以被投射到一个基础上，从而使得结果得到的权重是稀疏的，乘法数量减少了 2 倍 [51]（图 11）。对于特征提取而言，输入图像可以通过预处理被做得稀疏，可以实现 24% 的功耗减少 [49]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibk9icsDWAqcxiaTUcL5gDTcuXM4PTbjyKcVjukdiaMf2771icwt3p0YvhkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 11：基础投射（basis projection）后的稀疏权重 [51]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 DNN 而言，MAC 和权重的数量的减少可以通过一个被称为剪枝（pruning）的过程来移除权重而实现。[60] 首先探索了这个方面，其中对输出有最小影响的权重被移除了。在 [61] 中，剪枝被用在了现代 DNN 上来移除小权重。但是，移除权重并不一定会实现更低的功耗。因此，在 [62] 中，权重的移除方式是基于一个能量模型（energy model），从而可以直接最小化能量消耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[48, 51, 63, 64] 提出的专用硬件利用了稀疏权重来提升速度或减少能量消耗。在 Eyeriss [48] 中，处理元件被设计成：当输入为 0 时，直接跳过读取和 MAC，最后实现了 45% 的节能。在 [51] 中，通过使用专用硬件来规避（avoid）稀疏权重，能量和存储成本分别被减少了 43% 和 34%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;C. 压缩&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据的传输和存储在能耗和成本方面都是一个很重要的因素。特征提取可以得到稀疏的数据（比如 HOG 中的梯度和 DNN 中的 ReLU），而在分类中所使用的权重也可以通过剪枝稀疏化。这样所得到的结果是：压缩可以利用数据统计来减少数据传输和存储的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者已经探索利用了多种形式的轻量级压缩来减少数据传输。无损压缩可以被用于减少流入和流出芯片的数据传输 [11, 54, 64]。在 [65] 中，简单游程长度编码（simple run-length coding）减少了多达 1.9 倍的带宽，这是在理论上的熵限制的 5%-10%。向量量化（vector quantization）等有损压缩也可被用于特征向量 [51] 和权重 [8, 12, 66]，这样使得它们可以以较低的成本而存储在芯片上。一般而言，压缩/解压的成本是在几千 kgates 的量级上，具有最小的能量开销。在有损压缩的情况下，估计其对表现的准确度的影响是很重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;七、混合信号电路中的机会&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大部分数据传输都发生在内存和处理元件（PE/processing element）以及传感器和处理元件之间。在这一章节，我们将讨论这可以如何通过混合设计的电路设计来解决。但是，电路的非理想因素（circuit non-idealities）也应该被考虑到算法设计中；这些电路可以从第六节中讨论的精度减少的算法中受益。除此之外，因为训练通常是通过数字（digital）的方式进行的，ADC 和 DAC 的开销应该在系统评估时被考虑进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管空间架构的改进让存储和计算的位置更近了（即集成到处理元件中），但要将计算和存储本身整合到一起，还需要一些努力。比如说，在 [67] 中，分类被嵌入到了 SRAM 中。特别地，其字线（WL/wordline）是由一个使用了一个 DAC 的 5 位特征向量驱动的，同时其位单元（bit-cells）存储了二元权重 ±1。位单元的电流实际上是特征向量的值和存储在位单元中的权重值的乘积；其来自列的电流被加到一起以对位线放电（BL 或 BLB/bitline）。然后一个比较器被用于比较结果得到的点积和一个阈值——特别是差分位线的符号阈值（sign thresholding）。因为位单元的变化，这可被认为是一个弱分类器，而且需要 boosting 来将这些弱分类器组合起来形成一个强分类器 [68]。这种方法比从 SRAM 进行 1 位权重读取要节能 12 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的研究工作也提出了使用混合信号电路来减少 MAC 的计算成本。[69] 表明，使用开关电容器来执行 MAC 可以比数字电路能效更好，不管是在 ADC 还是 DAC 方面。因此，矩阵乘法可以像 [70] 提出的那样被整合到 ADC 中，其中用于 Adaboost 分类的乘法中最显著的部分是使用开关电容器以 8 位逐次逼近格式（8-bit successive approximation format）执行的。这在 [71] 中进行了扩展，使其不仅可以执行乘法，还能在模拟域（analog domain）上进行累加。据估计，3 位和 6 位就足以分别表征权重和输入向量了。这能让计算更接近传感器，并可以将 ADC 转换的数量减少 21 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要进一步减少来自传感器的数据传输，[72] 提出在传感器的模拟域中执行整个卷积层（包括卷积、最大池化和量化）。类似地，在 [73] 中，整个 HOG 特征可以在模拟域中计算，可将传感器带宽减少 96.5%.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;八、高级技术中的机遇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此章节，我们将讨论如何使用高级技术取得上一章节所说的数据传输问题。在参考文献 [47] 和 [74] 中分别提到的使用 embedded DRAM (eDRAM) 和 Hyper Memory Cube (HMC) 这样的高级存储技术来减少 DNN 中权重的能量访问成本（energy access cost）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在直接将乘法（multiplication）集成到高级非易失性存储上已经有了大量研究，使用他们作为电阻元件。具体执行乘法时，其中电导设为权重，电压作为输入，电流作为输出。其他工作就是把克希霍夫电流定律的电流值合计起来。在 [75] 中，忆阻器（memristor）被用于一个 16 位的点积运算的计算，其中 8 个忆阻器每个存储 2 位；每个忆阻器执行 1 位 X2 位的乘法计算，那么 16 位的输入需要 16 次循环来完成。在 [76] 中，ReRAM 用于计算 3 位输入和 4 位加权的乘积。与混合信号电路类似，其运算的精确都很有限，同时必须考虑把在 ADC 和 DAC 的转换开销（conversion overhead）计入总成本，特别是当在数字域中训练权重时。可以通过直接在模拟域中训练来避免转换开销，如 [77] 中制造的忆阻器阵列那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，将计算嵌入传感器本身或许具有可行性。对于从传感器读取数据的带宽占了大部分系统能耗的图像处理来说部分有用。比如，一个 ASP 传感器能被用于计算输入地图，随着压缩而以十倍的比例减少传感器带宽。一个输出梯度带宽也能减少计算和后续处理引擎的能耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;九、手工提取的特征 VS 机器学习的特征&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于机器学习的特征，如通过 DNN 学习的特征，手工提取特征的方法有更高的能量效率是以牺牲准确率为代价的。对于手工提取的特征来说，其计算量更少并且支持位宽减少。不仅如此，手工提取的方法需要更少的数据传输，因为特征的权重值不是必须的。两种方法的分类权重都是可程控的。图 12 中比较了 HOG 特征提取与 AlexNet 中卷积层、VGG-16 的卷积层的能量消耗，数据来源于在参考文献 [51] 和 [48] 中制作的 65nm 芯片上的性能表现。需要说明的是 HOG 特征提取与视频压缩（实时的高清视频每像素 1 纳焦）的能量消耗差不多，因此 HOG 特征是一个很好的基准来确定近传感器能量消耗的可接受值；但是，DNN 目前需要消耗比 HOG 多几个数量级的能量。我们希望在这篇论文中所强调的一些可以作为设计契机的地方将能够缩小两种方法之间的能量消耗差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibwkvEQdia8Aiay2HjiagsNk8C42vOkAVA5xMuNrdB54xtp4ibUibiaZ54Daicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 12. 能量 VS 准确率：手工提取特征和机器学习特征之间能量对比准确率的权衡比较。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;十、总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是一个非常重要的研究领域，在各种级别的硬件设计的创新上有许多有潜力的应用与机遇。在设计过程中，权衡准确率、能耗、吞吐量与成本是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于数据传送控制着能量消耗，最近的研究主要集中在维持准确率、吞吐量、成本的同时，减少数据传送。这意味着选择带有良好存储层级的架构，比如一个空间阵列（spatial array），以及开发在低成本存储层级上能增加数据重复使用的数据流。对算法与硬件进行联合设计，减少位宽精确度（bitwidth precision），增加稀疏（sparsity）与压缩，这些手段被用于最小化数据传输。有了混合信号线路设计和高级技术，通过将计算嵌入或接近传感器和存储，计算也就更接近数据源了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也应该考虑在这些不同层级上的交互。例如，通过硬件友好的算法设计而实现的位宽减少可以通过使用混合信号电路和非易失性存储来减少精度上的处理。通过高级技术减少内存访问的成本，这能带来更节能的数据流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;致谢与参考文献（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文下载本论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Dec 2016 13:46:44 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 量子计算新突破点：电子-光子的「闲聊」</title>
      <link>http://www.iwgc.cn/link/4048023</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自phys&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibicFMXK78Y42OwJjHcSHnZ4fZAhr9djsKyfrZDxpAx4dFNLYic7yiczYXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进一步实现基于硅的量子计算机，普林斯顿大学的研究者已经建造了一个可以让单个电子传递其量子信息给光粒子的设备。光粒子也就是光子，在接收信息之后可以充当信使从而把所接收的信息传给其他的电子。由光子所创造的这种连接关系构成了量子计算机的回路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项已在 Science 上发表的研究，是普林斯顿大学和加州马利布休斯研究实验室共同指导完成的，展现了他们 5 年多努力的成果。这 5 年多的研究中，他们为单个电子和光子之间的对话来打造强大的能力支撑，据 来自普林斯顿大学的物理教授 Jason Petta 所说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「就像人类之间的互动一样，一个良好的交流是要以很多事情的铺垫完成为前提的，比如说帮助交流双方讲同一种语言等，」Petta 说。「我们能够使电子态的能量与为光粒子的共振，从而使电子和光子能够互相对话。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项发现将帮助研究者运用光来联系单独的电子，这些电子充当量子计算机的比特也即是量子计算机里最小的数据单元。一旦实现，量子计算机将是先进的设备，其能够运用微小粒子（如电子）实现高级计算，这些微小粒子遵从量子定律而不是日常生活中的物理定律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在每天所使用的计算机中每一位比特的值要么是 1 要么是 0。量子比特（qubit）可以是 0 与 1 之间的一个值，或同时都为 0、同时都为 1。这种叠加就是为大家所熟知的量子特性，能够让量子计算机处理现在的计算机所不能解决的复杂问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单个量子计算机已经通过囚禁粒子和超导体建造出来了，但是技术挑战减慢了基于硅的量子设备的研发进度。在构建量子计算机的时候，硅是非常诱人的材料，因为硅的价格不贵而且已广泛用于今天的智能手机和计算机的设备制造中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员们在他们的设备里囚禁了一个电子和一个光子，然后把电子的能量用这样的一个方式转移给光子。通过这样的耦合使得光子把所携带的信息从一个量子位转移到位于一厘米之外的另一个量子位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子信息是极度脆弱的，即使是来自所在环境里最轻微的干扰，将会导致其携带信息的全部丢失。光子对抗干扰的能力更加强健，此外光子不仅能够在量子计算机的回路中将携带的量子信息从一个量子比特传递到另一个量子比特，而且可以在量子芯片之间通过电缆传递。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使这两种不同类型的粒子能够互相「交流」，研究员们还必须建立一个提供适宜「交流」环境的设备。首先，休斯研究实验室（一个由波音公司和通用汽车拥有的研发实验室）的 Peter Deelman 装配出了一个半导体芯片，这个芯片由多层的硅和硅锗构成。这个装配的半导体芯片在其芯片表面之下囚禁了单层的电子。下一步，普林斯顿大学的研究员们在装置的顶部铺设了细微导线，每根导线的宽度只有人头发丝的几分之一。这些直径为毫微米的导线所传导的电压创建了能够囚禁单个电子的能级相图，而这些囚禁的电子将会在限制在硅的被称为双量子点（double quantum dot）的区域里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员们用这些导线来将囚禁电子的能级调整到与光子所匹配的程度，光子是由芯片顶层超导腔所囚禁。在这项研究发现之前，半导体的量子比特仅能被其相邻的量子比特耦合。通过光来耦合量子比特，将可以在位于芯片相对两端的量子比特之间进行信息传递。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;电子的量子信息无非就是其处于双量子点的 2 个能量穴（energy pocket）其中之一的位置信息。电子能占据两个能量穴之一或同时占据两个能量穴。通过控制用于设备的电压，研究员们就能够控制电子在哪个能量穴中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们现在有实际转移电子量子态给囚禁在超导腔中的光子的能力了，」普林斯顿的物理系研究生也是论文的第一作者 Xiao Mi 说。「这一过程之前从未在半导体设备中实现过，因为在能够转移电子的量子信息之前其量子态就已丢失。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个装置中能成功实现量子态的转移，归功于一个新的回路设计，这个回路在设计时能够让铺设的细微导线与量子比特之间的位置更近从而能够减少来自其他电磁放射源的干涉。为了减少这类噪音，研究员们在通向这个装置的导线中放置了能够过滤掉无关信号的滤波器。这些金属导线同时也充当了量子比特的保护盾。通过这些操作保护，相比于之前的实验，他们的量子比特所接受到的噪音量能够有 100 到 1000 倍的减少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，研究人员计划拓展该设备使其能发挥电子的自旋特性。「长期来看，我们想让这个自旋和电荷耦合在一起的系统能自己造出一个可以电控的自旋量子，」Petta 说。「我们发现我们能讲一个电子与光相干耦合在一起，这是实现自旋光耦合的重要一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德国亚琛工业大学量子信息研究所的一位物理学家 David DiVincenzo 虽然没有参与这项研究，但他在 1996 年参与了一篇非常有影响力的论文，该文概述了创建量子计算机所需的五个最低要求。对于普林斯顿 HRL 的工作，DiVincenzo 虽没有参与，但他说：「为了找到合适的条件组合实现单电子量子比特的强耦合条件，已经花了很多精力了。我很高兴地看到有人发现了一个参数空间的区域，在这个区域中，该系统可首次进入强耦合域。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://phys.org/news/2016-12-electron-photon-small-talk-big-impact-quantum.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Dec 2016 13:46:44 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 日本科学家首次成功演示基于自旋电子学的人工智能</title>
      <link>http://www.iwgc.cn/link/4048024</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自phys&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日本东北大学的研究者有史以来第一次成功演示了基于自旋电子学的人工智能（spintronics-based artificial intelligence）的基本操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibotCXgbibbiaqzI4iaxU93ZJbiaOC50tclx0xzkSXGb2sgBVIe4ZVHgldjA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;图 1：(a) 在本演示中用作人工突触的人工制造的自旋电子器件的光学照片。图中也展示了用于电阻切换的测量电路。(b) 该器件的电阻和被施加的电流之间的关系，表现出了类似模拟的电阻变化。(c) 安装在一个陶瓷封装上的自旋器件阵列的照片，这种器件可被用于开发人工神经网络。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟生物大脑处理信息的方式的人工智能可以快速执行复杂和精细的任务，比如图像识别和天气预测。人工智能近些年来得到的关注越来越大，并且也已经出现了很多有价值的实际应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前的人工智能都工作在传统的框架上——即基于半导体的集成电路技术。但是，半导体器件并不具备人脑的紧凑型和低功耗特性。为了解决这一难题，实现用作突触的单个固态器件是非常有前途的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东北大学的 Hideo Ohno 教授、Shigeo Sato 教授、Yoshihiko Horio 教授、Shunsuke Fukami 副教授和 Hisanao Akima 副教授的所组成的研究团队在他们最近研发出的自旋电子器件（spintronic devices）中开发了一个人工神经网络，其采用了微尺度磁性材料（micro-scale magnetic material），如图 1 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和传统的磁性器件不同，他们所用的自旋电子器件能够以一种模拟的方式记忆 0 到 1 之间的任意值，因此可以执行学习功能，类似于大脑中的突触。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibnbhX1oNLXK5iaqSjBZSnqbLiaqN1AkR7OSxV7W3l5twLK90SgGVvZIgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：开发出的人工神经网络的框图，包含了 PC、FPGA 和自旋电子阵列（SOT/spin-orbit torque，自旋轨道转矩）器件。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用这个开发出来的网络（图 2），这些研究者实验了关联记忆操作（associative memory operation）——传统计算机还无法实现这样的运算。经过多次试验之后，研究者确定这种自旋电子器件具备学习能力——他们开发出来的人工神经网络可以像人脑一样成功将它们记忆中的模式和有噪声的输入版本关联起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个概念证明的演示有望为人工智能技术开辟新的发展空间——在减小紧凑尺寸的同时还能实现高速处理的能力和超低的功耗。这些特性应该有助于将人工智能推广到更广泛的社会应用领域，比如图像/声音识别、可穿戴终端、传感器网络和护理机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3JuibXicwMt0LDy71vIwaaSQqqpIicTKiaibwvzzBu0LpULavEYbcSFXuibqWGfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 3. 三类模式，I、C 和 T，展现在 3×3 的框里，被用于关联记忆操作实验。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;原文链接：http://phys.org/news/2016-12-world-spintronics-based-artificial-intelligence.html&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Dec 2016 13:46:44 +0800</pubDate>
    </item>
    <item>
      <title>圣诞快乐！来听听人工智能为这个圣诞节献上的歌曲</title>
      <link>http://www.iwgc.cn/link/4048025</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：鹿者也&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着圣诞节的到来，各种换汤不换药的圣诞歌曲又在挑战人们审美疲劳的极限。虽然不知道歌手们自己是如何完成每年的旧瓶装新酒的创作，但今年的圣诞歌曲中确实混入了一朵奇葩，如果这几个由人工智能编写的闹腾旋律姑且也能算是歌曲的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多伦多大学的博士生楚航近日发布了他的新项目，一首完全由人工智能看着一棵圣诞树来编曲，填词创并朗诵的一首神奇的小调，并配有一个火柴人摇摆起舞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=s03585ecziu&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;楚航通过建立一个层级递归神经网络（Hierarchy RNN）的模型，然后收录大量音乐数据，从而由人工智能分析大体的音乐结构特点，发现并总结多首相似风格的音乐中存在的类似的特征，再以新颖的构建框架建立多层神经网络模型，最终通过输入一副画面，便能生成相应主题的流行音乐。研究项目中每层网络对应生成不同的音乐成分，并且每一层都是一个「双层 LSTM（double layer LSTM）」且相互关联，让最终输出的音乐具有更高的质量和丰富性。在多层的构筑框架下，还可以在生成音乐之外编出新颖的舞步和歌唱的人声。楚航便是在这样的构建基础下制作了应用 Neural Karaoke，Neural Dancing 以及 Neural Story Singing。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;课余兴趣的游戏之作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员楚航是多伦多大学（University of Toronto）的在读博士生，导师为人工智能界大牛 Raquel Urtasun 以及 Sanja Fidler，现主要致力于研究学习 CV（Computer Vision）。此前康奈尔大学（Cornell University）获取硕士学位，于上海交通大学获取本科学位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人主页：&lt;/span&gt;&lt;span&gt;http://chuhang.github.io/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是作为博士生楚航在多伦多大学的第一年，过往研究主要集中于机器学习（machine learning）以及 2D-3D 转换建模等，现今在跟随导师主要研究 CV 的同时，想要做一些有趣的相关研究项目，能够将以往学习的知识联合运用，由此产生了动力并着手于这项人工智能音乐项目的研究。并在两周的时间里得到了目前的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多层构建 RNN 的方式使得 AI 输出的音乐内容更加丰富&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neural Karaoke 的模型核心理论名为分层递归神经网络。在当前的人工智能研究中，RNN（时间递归神经网络 recurrent neutral network 和结构递归神经网络 recursive neural network 的统称，但通常意义上单指时间递归神经网络，本文亦是）是一项非常重要和主流的机器学习方法。相较于深入学习强化单个 RNN，楚航在项目中提出了新的神经网络构建框架，即层级递归神经网络。通过在单个 RNN 上再度构建一个新的 RNN，使模型变得多层立体（hierarchical），并让每层神经网络对应生成单独的音乐成分。而每一层所对应的音乐成分并不是固定不变的，例如在楚航的研究中，最底层的（base layer）RNN 负责生成音乐旋律，然后在旋律上关联按键音，接着在其基础上再构建一层 RNN 负责生成和弦，而后构建出第三层 RNN 对应生成鼓点，最终输出一首结构丰富的的音乐。模型的具体结构如图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8AXdZ3Y3GvExKagAzu3Juibpdsv0Pt8ZLgUkg1laj5X4HbCm99GbuId4QQrrykiayEbukG8Kk3jaIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在建立多层神经网络的同时，每一层的 RNN 模型中都建立了双层 LSTM（long-short term memory），并让不同层次相互关联，以弥补 RNN 在短期记忆上的匮乏。而对于音乐的组成成分，楚航团队尝试做了一些拓展，除了最基础的旋律+和弦+鼓点外，团队还尝试加入了舞蹈以及歌词，这两项尝试也就对应到了楚航论文中的 Neural Dancing 和 Neural Story Singing。如果能把现有的所有成分融入到一个模型中，理论上可以做到输入一副图片，然后得到一首相应风格的歌曲并伴随着小火柴人的舞步和歌声。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这项研究的核心价值体现，楚航表示或许应当是提出了一个新的人工智能应用场景，给学界带来一点新的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;实验室中的 Neural Karaoke，谷歌 Magenta 与 索尼 Flow Machine&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除却楚航的 Neural Karaoke，谷歌的 magenta system 团队和索尼旗下的 CSL 研究室也各自发布了相似的研究成果。谷歌的 magenta 团队发表的人工智能作曲应用 TensorFlow 的运作方法主要基于深度学习下的增强学习（deep reinforcement learning）和极限类比（maximum likehood）。通过构建一个生成音节的神经网络（Note-RNN）, 然后建立 LSTM 来预测目标音乐规律中的下一个音节，然后通过 RL 法来将其改善。再由音乐理论和奖励基质（reward base）共同构成的奖励方程确定输出音节，而后送入下一个音节网络。Magenta 团队表示，这样结合了 ML 的 RL 调节法不单单可以用在产生美妙的曲调，同时还能够显著的减少神经网络运作中不必要的无用及失败模型。对于 magenta 团队所使用的方法，楚航表示这和他使用的多层神经网络框架并不冲突，两者的应用应该是平行且互补的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而索尼的 CSL 研究室虽然并没有发表相关论文，但也同样发表了他们的应用成果，名为「FlowMachine」的软件，并请专业音乐人 Benoît Carré 填词，最终带来了披头士风格的歌曲「Daddy』s Car」。并且 FlowMachine 和谷歌团队的 TensorFlow 都将在不久后于各自的平台发表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;让大众以更低廉的成本感受到原创音乐的乐趣&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;楚航表示他今后的研究方向依然是会着重于 CV 和建模方面。而 AI 作曲作为一个课余想到的课题，也确实有打算做下去，将其加以改进。例如融合多层建模和增强学习，或者增加音乐情绪的研究，亦或是输入和输出的双向性和逆转性，都是很有趣研究方向。并且目前正在召集感兴趣的同好加入项目组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;楚航研究人工智能编曲的初衷就是基于有趣。对于应用的方向，可能会希望建立一个类似社交网站的工具，让大家上传分享各自独特风格的音乐和舞步，带来更多的可玩性。亦或是使用廉价的机器人，节省人们消耗在投资，制作音乐上的金钱，更加容易地听到全新的音乐，享受更简单的原创音乐等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Dec 2016 13:46:44 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 新论文解读（情感分析、机器阅读理解、知识图谱、文本分类）</title>
      <link>http://www.iwgc.cn/link/4048026</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;本期的PaperWeekly一共分享四篇最近arXiv上发布的高质量paper，包括：情感分析、机器阅读理解、知识图谱、文本分类。人工智能及其相关研究日新月异，本文将带着大家了解一下以上四个研究方向都有哪些最新进展。四篇paper分别是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Linguistically Regularized LSTMs for Sentiment Classification, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples, 2016.10&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: center; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;1.Linguistically Regularized LSTMs for Sentiment Classification&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Qiao Qian, Minlie Huang, Xiaoyan Zhu&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;sentiment classification, neural network models, linguistically coherent representations,&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;利用语言资源和神经网络相结合来提升情感分类问题的精度&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在LSTM和Bi-LSTM模型的基础上加入四种规则约束，这四种规则分别是: Non-Sentiment Regularizer,Sentiment Regularizer, Negation Regularizer, Intensity Regularizer.因此，新的loss function变为:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGUQ4jUBcxvMU3DmW2iaf6GEbnt1gn1Do0QQCbVutXibL3OQEMial3WiaiawsQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的规则约束对应不同的L函数&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、Movie Review (MR)&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://www.cs.cornell.edu/people/pabo/movie-review-data/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、Stanford Sentiment Tree- bank (SST)&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://nlp.stanford.edu/sentiment/treebank.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、Neural Networks for Sentiment Classification&lt;br/&gt;&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;Empirical evaluation of gated recurrent neural networks on sequence modeling&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;Hybrid speech recognition with deep bidirectional lstm&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、Applying Linguistic Knowledge for Sentiment Classification&lt;br/&gt;&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;Sentiment classification of movie reviews using contextual valence shifters&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出了一种新的基于语言资源约束和LSTM/Bi-LSTM的模型用于情感分类，并通过在MR和SST数据集上的实验和对RNN/RNTN,LSTM,Tree-LSTM,CNN的效果对比证明了这一模型的有效性。除此之外，本文还基于不同的约束进行了实验，证明的不同的约束在提高分类精度上的作用。本文实验丰富，效果的提升虽不显著，但新的模型确实在不同程度上克服了旧模型的一些不足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: center; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;2.End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: left; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Yang Yu, Wei Zhang, Kazi Hasan, Mo Yu, Bing Xiang, Bowen Zhou&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;IBM Watson&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Reading Comprehension, Chunk extraction, Ranking&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;针对答案非定长的阅读理解任务，本文提出了DCR（dynamic chunk reader）模型，来从给定的文档中抽取可能的候选答案并进行排序。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出的模型结构共分为四部分，&lt;br/&gt;1、Encoder Layer&lt;br/&gt;如图所示，这部分是用双向GRU分别对文档（Passage）和问题（Question）进行编码。&lt;br/&gt;2、Attention Layer&lt;br/&gt;该层采用的方法与相关工作中的mLSTM类似，文档每个时刻的状态hjp都与问题中的每个状态hkq进行匹配得到一个权重向量αk，然后再根据该权重向量对问题的GRU隐层输出hp进行加权求和，得到文档中该时刻状态hjp对应的上下文向量βj，两个向量hjp和βj拼接在一起作为该时刻新的表示vj。最后再将上述与问题相关的新文档表示v通过双向GRU，得到文档最终的表示γ。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGUPoJF20jibVAmYV7oKibnJibEPKfYTxJPBibXhXbyGuibJOllzoalfReBEkA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Chunk-Representation Layer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上一部分获得了与问题相关的文档表示γ，那么这部分则是考虑如何抽取候选答案，并获得候选答案的表示向量。本文提出了两种候选答案抽取方法，第一种方法是抽取所有满足训练数据中答案对应词性标注模式的候选项，第二种方法则是简单粗暴地确定一个候选项最大长度，然后遍历所有可能的候选项。至于候选答案的表示方式，本文将候选答案前向GRU的最后一个时刻状态和反向GRU第一个时刻状态拼接在一起作为最终候选项的表示。&lt;br/&gt;4、Ranker Layer&lt;br/&gt;已经获得了所有候选项的表示，那么接着就是对所有候选项进行打分排序。本文中打分是采用问题的表示和候选项的表示计算内积的方式得到的，本文训练过程中没有采用常见于排序任务的Margin ranking loss，而是先用softmax对所有候选项计算一个概率值，然后采用交叉熵损失函数进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文在SQuAD数据集上进行实验，提出的方法效果比之前两篇SQuAD相关paper的方法有较大的提升。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、SQuAD&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://rajpurkar.github.io/SQuAD-explorer/&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、数据集相关论文&lt;br/&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;br/&gt;2、模型相关论文&lt;br/&gt;MACHINE COMPREHENSION USING MATCH-LSTM&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在对文档和问题编码阶段，本篇论文提出的模型与之前mLSTM那篇paper有些相似。两篇论文中模型的主要区别在于：mLSTM那篇论文采用预测起始、终止位置的方法来确定答案，而本文则是先采用一些规则或Pattern的方法来抽取一些候选答案，然后再对候选答案进行排序。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;联系方式&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;有DL或者NLP相关话题，欢迎讨论。destin.bxwang@gmail.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: center; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;3.Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Amit Sheth, Sujan Perera, and Sanjaya Wijeratne&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Kno.e.sis Center, Wright State University Dayton, Ohio, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Semantic analysis of multimodal data，Machine intelligence,Understanding complex text，EmojiNet&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;利用知识和多模态数据来解决特定情况下的复杂文本的深层理解问题&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、现知识库在处理特定领域问题中的局限性及解决方法&lt;br/&gt;（1）知识库的杂乱&lt;br/&gt;解决方法：采用自动判别技术，领域知识库索引技术，利用实体和关系的语义去判别所给定知识库领域中的相关部分。&lt;br/&gt;（2）知识库数据的不完备和不充足&lt;br/&gt;解决方法：使用 human-in-the-loop模型在真实的临床数据和已有的知识库中去发现更多的实体与实体之间的关系。&lt;br/&gt;（3）知识表示技术和推理技术的局限性&lt;br/&gt;解决方法：在单个属性的表示中加入了三元组和软逻辑的解释能力及其相关概率值和理由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、新的研究应用&lt;br/&gt;（1）隐实体链接&lt;br/&gt;（2）表情符号语义消歧&lt;br/&gt;（3）理解和分析web论坛中关于药物滥用的相关讨论&lt;br/&gt;利用相关背景知识加强不同种类信息的信息抽取模型&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGUdRNloII9paYunslVUcgrO3CMvcIRPuQicA2HAOTowDKTrib0EaRyg6Ng/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、在健康领域中的文本理解模型&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGUV6L0MNXxHiadicy8MiccrExy6BBeA8EhiclnB5zJP9rRjjg4ez74u0ORLA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、使用感知器和文本资料了解城市交通情况&lt;br/&gt;(1)交通领域的概念关系网模型&lt;br/&gt;(2)概率图模型&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGU7LKNnvwGo54rUR9DSoORcD5MF3b0H3l01MXta2XEF4ic1TkDwHH1qnw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用领域知识关联不同模态下的上下文相关数据&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGUx2J3OgIWfsXW6zqhmibAqs37tkGuaRaJcssMAJ8PsOnibjXVBXKSynew/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文主要举例说明了知识将推动机器对内容的理解。总体来看本文像一篇综述性的文章，给出了在知识库创建过程中所遇到的问题的解决方案，同时以实际案例来阐述知识在我们实际问题中应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: center; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;4.AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Depeng Liang and Yongdong Zhang&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Guangdong Province Key Laboratory of Computational Science, School of Data and&lt;br/&gt;Computer Science, Sun Yat-sen University, Guang Zhou, China&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACNN; BLSTM; Text Classification&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出了一个新的深度学习的模型–AC-BLSTM的模型（即：将ACNN和BLSTM组合在一起），用于句子和文章层面的分类。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;AC-BLSTM模型可以分成四个部分,如Figure 1所示：&lt;br/&gt;1、输入: 输入是一个sentence，使用 ( L&amp;nbsp;d )的矩阵表示，其中L表示句子中的L个词，d表示每个词的词向量的维度&lt;br/&gt;2、ACNN(Asymmetric CNN): 传统的CNN采用的是 ( k&amp;nbsp;d ) 大小的filter，ACNN则把filter的过程分成 ( 1&amp;nbsp;d ) 和 ( k&amp;nbsp;1 ) 的两个过程，相当于是把 ( k&amp;nbsp;d ) 的filter做因式分解。&lt;br/&gt;这一层的输入是一个 ( L&amp;nbsp;d ) 的矩阵，对于n个尺度为( 1&amp;nbsp;d ) 和( ki&amp;nbsp;1 )的卷积层的输出是一个 [ (L - ki + 1)&amp;nbsp;n ]的矩阵，如下图所示，本文采用了3种不同的卷积核，所以输出是3种不同的[ (L - ki + 1)&amp;nbsp;n ]的矩阵（图中一个彩色的小方块表示 (1 * n)的向量）&lt;br/&gt;3、连接层: 为了给BLSTM构造输入，连接层将3种不同卷积层的输出，以Ct^i表示第1种卷积层为LSTM第t个time step贡献的输入，则LSTM网络的第t步输入Ct = [Ct^1, Ct^2, Ct^3]，其中t属于{1,2,…,L-K+1}, K = max{ki}&lt;br/&gt;4、BLSTM: LSTM能够很好的解决long time delay 和long range context的问题，但其处理是单向的，而BLSTM能够解决given point的双边的依赖关系，因此，本文选择了BLSTM网络层来学习ACNN输入的特征的dependencies&lt;br/&gt;5、Softmax层: 为了应用于分类问题，本文在最后使用全连接层和softmax函数来实现分类。&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglXKu8wicR1jC0vsicE1CgaGU0QwsAaHYricHQzX99LibTQS7jgzA817bBt17M5KvZb64ZdxcyZicYnJUw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;文章中使用的数据集&lt;br/&gt;1、SST-1&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://nlp.stanford.edu/sentiment/index.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、SST-2&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://nlp.stanford.edu/sentiment/index.html&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;3、Movie Review(MR)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://www.cs.cornell.edu/people/pabo/movie-review-data/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;4、SUBJ&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://www.cs.cornell.edu/people/pabo/movie-review-data/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;5、TREC&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://cogcomp.cs.illinois.edu/Data/QA/QC/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;6、YELP13&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://www.yelp.com/dataset_challenge&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、Yoon Kim于2014年在&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;Convolutional neural networks for sentence classification&lt;/span&gt;&lt;/a&gt;&lt;span&gt;一文中提出将词向量和CNN结合，用于句子分类的模型。在该文中，Kim将不同长度的filter的组合在一起，且提出了static或者可以fine-tuning的word embedding模型&lt;br/&gt;2、Zhou et al.则于2015年在&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;A C-LSTM neural network for text classification&lt;/span&gt;&lt;/a&gt;&lt;span&gt;一文中提出将CNN和LSTM叠加的模型，且使用固定的word embedding&lt;br/&gt;3、Szegedy et al.于2015年在&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;Rethinking the Inception Architecture for Computer Vision&lt;/span&gt;&lt;/a&gt;&lt;span&gt;中提出了ACNN模型，这减少了参数的个数且提高了模型的表征&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章主要贡献就是提出了一个AC-BSLTM的模型用于文本分类，亮点就在于：ACNN可以在减少参数的个数的同时通过增加更多的非线性性来提高表达能力，而BLSTM能够捕捉输入的两端的信息。两者的结合就提高了分类的精度。但事实上，这两个网络模型都是现有的，本文的工作感觉只是两个网络的连接，在本质上没有太大的改进，且在分类精度上的提高也比较有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Dec 2016 13:46:44 +0800</pubDate>
    </item>
    <item>
      <title>独家 | Yoshua Bengio研究生科研指导演讲：解读人工智能全貌和下一个前沿</title>
      <link>http://www.iwgc.cn/link/4034091</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Joshua Chou&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近期，Yoshua Bengio 在加拿大多伦多大学 Distinguished Lecture Series 面向计算机及工程方向的硕博研究生进行了一次题为「从深度学习到人工智能（From Deep Learning to AI）」的学术研究方向指导讲座，机器之心技术分析师 Joshua Chou 亲历了这个讲座，并对其中的关键内容进行了梳理和总结。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几经波折之后，人工智能终于要来了；它将给我们的社会带来巨大的变革，甚至可能会引发一场新的产业革命。毫无疑问，机器正变得越来越智能，而在这一次智能革命的中心，由大脑所启发的深度学习正在扮演着极其重要的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia66azyWSWOzAjcQHicpNb4JyfVaZR3sd4hG3YpiayMfkrcAFkfpdftkB9Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴能够参加 Bengio 教授的演讲，并且希望能够将他传递给学生的观点再分享给更多的人。这篇文章中的一些材料来自其演讲所引用的论文，尽管我没有足够的时间仔细阅读所有这些论文，但我将尽我所能给出这些论文的概述以及它们与这个演讲的关联。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度学习领域的突破&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia67IGN1aibJKrULCia2gGPMqiaClp8tibLyHfiaxb7ABxwiaiaX7bmH2frvovBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先值得一提的是，多亏了加拿大高等研究院（CIFAR）的不懈努力，深度学习领域内的很多突破都诞生在了加拿大这片土地上。过去十年来，CIFAR 一直在给许多教授的团队提供资助，其中包括多伦多大学的 Geoffrey Hinton 教授、纽约大学 Yann LeCun 教授和这一次的演讲者、蒙特利尔大学的 Yoshua Bengio 教授。今天，深度学习科学家已经找到了训练更深度的神经网络的方法。但在此之前，科学家们还尝试过很多不成功的训练方法，而不成功的原因则是那时候人们对训练更深度的神经网络还缺乏了解。事实证明，深度（depth）问题是很重要的，深度学习也由此得名——而它本质上是之前十年在神经网络之上的研究的延续。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习的每一个典型案例都涉及到分段非线性单元（piecewise non-linear unit），这一成果是在多伦多大学和蒙特利尔大学的研究成果之上不断积累得到的。这些成果表明，我们可以使用这种分段非线性变换（piecewise non-linear transformation）来训练比之前远远更深的神经网络。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年里，这一重要的研究结果为我们带来了语音识别等应用（第一款产业界的语音识别应用出现在 2010-2012 年之间）。到 2012 年的时候，只要你有一台安卓手机，你就有了一个可以为你进行语音识别的神经网络（「okay Google」）！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个远远更大的领域是计算机视觉，它也在一两年之后实现了应用。同样，来自多伦多大学的研究突破也发挥了重要的作用，这些研究将之前的很多思想都集中了起来，并且还带来了更大的改进。这些改进不仅仅是在算法上，而且也涉及到借助硬件的进步来实现更快的计算处理。比如说，研究者发现最初为图形和视频游戏处理所设计的 GPU 碰巧非常适合用来训练神经网络；几年之后，斯坦福大学教授李飞飞启动了 ImageNet 数据集项目，该数据集带有大量有标注的数据，已经帮助许多研究者和开发者实现了很多深度学习应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前来说，深度学习主要还是基于监督学习（supervised learning），并且还需要数百万有标注的图像来进行训练。实际上，我们可以看到在过去的四五年里，这些深度神经网络的准确度一直在不断提升（了解更多可参阅论文《ImageNet Classification with Deep Convolutional Neural Networks (Sutskever, Hinton, Krizhevsky)》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 用机器学习实现人工智能的关键要素&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要让机器学习系统接近人类水平的表现，我们通常需要一些关键的要素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你需要大量乃至巨量的数据。为什么呢？因为智能意味着正确地决策；而为了做出正确的决策，你需要知识。研究者所面临的一个核心问题就是如何好好使用知识。这个世界很复杂，如果要让机器理解世界的水平达到人类同样的程度，那么我们就将需要给机器描述大量的知识。为此，我们需要通过大量的数据来训练机器，从而使其能够以一种类似于人类能力那样微妙的方式来进行理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，为了利用数据，模型还必须要足够灵活。（许多传统的统计模型仅仅是将数据编译成不同的参数集合，这样的模型是很死板僵硬的。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，为了训练机器，我们还需要大量的算力，这方面我们早就实现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6nSJdMoAOWHtAjCzzFBufPsuibHLgt5b1ZpowmmCm6TySNBSwxKb7INQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，关于神经网络还有一个更加微妙的细节：一旦你训练好了一个神经网络，你就可以非常高效地使用它，而且仅需要非常少的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，另一个重要的要素是这个世界中已有的假设，它们可以被看作是我们训练的先验知识，它们非常强大，足以应对「维度灾难（curse of dimensionality）」。维度灾难是这样一种情况：当存在大量的变量时，配置（configuration）的数量也将随之指数级增多；因此我们只能针对大多数配置寻找正确答案，而不是针对所有的配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在后面的章节中，我们将重点关注最后一个要素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 学习中的维度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要的假设本质上都是关于组合的世界的假设，它们内建于深度网络之中——这解释了深度网络的表现如此良好的原因。我们认为知识生成来自于我们将碎片组合起来的过程，而我们推导给定的答案也是通过将碎片化的信息构建到一起。比如说，语言就有这样的性质——我们定义语言中的每一个概念都是通过组合已有的概念进行定义的。而在之前的机器学习领域，这还是无法实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更确切来说，在深度网络上，我们有两种实现组合性（compositionality）的方式。其中一种可被看作是一种并行的方法，而另一种则是序列式的方法。人类可以并行地选择不同的概念来进行组合，然后以非并行的方式来描述世界。这就是分布式表征（distributed representation）的理念，这意味着每一个对象都会被许多属性（这在神经网络中被称为特征（feature））描述，而这些属性配置的数量将会随属性数量的增长而指数式地暴增。序列式的方法则必须涉及到这一事实：当我们将在并行步骤中所获得的结果组合起来时，我们每一次都要执行一个运算序列（sequence of operations）（可以将这看作是神经网络中的多层面特征学习）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 非分布式表征（Non-distributed Representations）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这只是 Bengio 教授在深入到分布式表征之前所给出的一个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习算法工作的方式都是获取一个输入空间（input space），然后将其分解成一个决策树（decision tree）（想一想在一些 n 维空间中分隔点的超平面）。对于该决策树中的每一个区域，我们都有一个来自构成那片区域的样本的答案（值得注意的一个重点是：可区分的区域的数量与参数的数量成正比）。很多人在很多时候会认为这是一个解决问题的好办法，但我们还能做到更好吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 对分布式表征的需求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6c2DmV6FR91mZJ1qdZt02x7EBxPOq0Np29FS4icnPqyFNx5dUMjYYURw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从统计学的角度来看，需要了解的一个重要问题是参数的数量（或样本的数量）与可区分的区域（这能给我们提供关于其函数复杂度的见解）之间的关系。在这里，我们需要思考一个重要的问题：我们可以泛化到我们从未见过其中任何数据的区域吗？在这种情况下，答案是否定的。我们需要看到每一个区域的数据，因为每一个区域的参数都是特定的（对于每一个区域而言，都存在一个单独的参数集，其中至少有一个参数能告诉你答案对应于哪一个区域）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6pibOa9cLEKicUBr2q6RXW1YAHoAmCbosXDnjZ1ibwyc2IyuvpPe0oiaf4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们使用分布式表征时，我们的做法是给每一个输入都匹配一个属性集合。然后我们定义以组合式的方式获得的输入空间的区域。比如说，让该属性参数属于一个二元集。对于每一个属性，我们都可以将其看作是能够将一个空间分隔为两个区域的超平面。其中一个区域对应的属性值为 1，另一个区域对应 0。由此，可以很容易理解当属性（超平面）的数量增长时，可区分的区域数量将随之指数式的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的问题是我们希望学习的功能能否通过这种方式进行分解？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6ibWZVjwAmjZNdPDz9iaWXosCUC0G4IVQkgMDiapQBvgWG23u93RYF72icA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的窍门在于我们会对这个世界进行假设。幸运的是，这个世界是组合式的，因此也遵循这一假设。比如以图像作为输入为例，你可以思考一下与这张图像相关的属性向量——是关于男性/女性、杯子/不是杯子、孩子/成年人……你可以使用这些属性向量描述很大图像集，而我们无法获得这个数量的用于学习的样本。但是，如果我们将这个空间分隔成可区分的区域，我们就可以分别从这些属性中学习。总的来说，在无需涉及其它特征而导致的指数级配置增长的情况下，每一种特征都可以被学习到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 深度的先验知识（Depth Prior）可以发挥巨大的作用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6chzL12wenfUuXeT5BvBU4fxjFU55CV6yPEeN9APKUd8gt1JYdXSUmw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用了一个足够深的神经网络，那么你确实可以有效地表征一些类型的功能；但是大多数功能使用深度网络也没有优势。如果你希望学习的功能落在这个非常严格的组合式类型范围内，那么你就能通过深度网络获得巨大的好处。有很多论文都说明了，除了分布式表征之外，你也可以有很多的层（layer），当我们计算区域的数量时，我们也可以看到区域的数量会随层的数量指数级地增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia60OpHDZCOhQYkSP9vnJ6ZrAVQbEqYMF3sr66hGvbibAd0DC3DibX38eww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 并不需要凸性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去，研究者真的会害怕局部极小值（local minima）的麻烦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6DvCtCadyDTAjhfcW7I6wqMIbHhWetdEDtICpdicsicHjicoOzRA5D1nsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这一主题的一篇论文《The Loss Surfacesof Multilayer Networks (by Choromanska et al. 2015)》通过实验表明：随着问题的维度的增长，你的解决方案的损失（loss）的变化会减少。所以基本上来说，在最佳方案和最差方案之间的差距会缩小，而你所有的局部极小值都将最终变得差不多一样。所以非最优解决方案（non-optimal solution）的思想已经差不多一去不复返了，因为人们并没有真正解决这个问题，而只是将其变成了一个非问题（non-issue）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6EQ4IiaDicJsZ9ibTh6qk3gUYsM81UZZCBswvR4aWhsPN0yzHmHCa2rHsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个观点本质上是来自于这样一种直觉上经验：局部极小在低维度条件下是最佳的，但鞍点（saddle point）主导了高维。你可以这样思考：任意一个所有方向都是上升的局部最优（鞍）点随维数指数级变小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;9. 超越模式识别、走向人工智能的深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6jNv0OuuKOtomt0bXgItutXFfvlfepgOqpXRcFHwzibLiaqyK90JImicWw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络正在从其传统的保留地（目标识别、模式识别等）走向传统上与标准人工智能相关的领域（推理、逻辑等）。在这一运动中，Bengio 领导的研究组曾经发现了一种被称软注意（soft attention）的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. 深度学习的注意机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia65oLkcibZRbKe9gRRJXsxKRLl7Ra0gfo1neKwHFPuZ51kzuLwN9Zjicfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个最好通过一个例子来解释。当我们在从左向右一次翻译一个词地将法语翻译成英语的时候，如果能够注意到每个词在原法语句子中的位置，那么就会给我们的翻译结果提供很大的帮助；因为在一个句子中，一个词可能会给其后面的词带来很大的影响。事实已经证明，这种注意（attention）的概念是很重要的。会出现这种情况的原因是我们使用了反向传播。我这么说是因为我们使用了涉及参数的一些损失函数的梯度，我们需要所有的计算都是可微分的（你可以将其看作是可微分的注意）。因此，除了注意特定的位置，我们还在每一个可能的位置上有一个概率（其对应于权重）。所以当我们根据梯度改变权重时，我们本质上只是将注意转移到了另一个地方（参见论文《Neural Machine Translation by Jointly Learning to Align and Translate（Bahdanau, Cho, Bengio）》了解更多。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 深度网络的低精度训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让我们的算法对更多的硬件友好，有很多的研究者做了很多的工作。其中首要的努力方向是在训练深度网络时使用更低的精度。这个方向的研究涉及到通过低精度的训练来实现更高准确度的神经网络，这能让我们可以在更大型的数据集上训练更大型的网络。Bengio 引述的一篇论文讨论了训练的那个部分应该被削减以维持高准确度。我发现（一个通用的经验法则）：除了任何我们希望保持高精度累积计算（accumulation computations），其它所有部分（权重、梯度等）差不多都可以被削减掉（参见 Guptaet al, arXiv, Fec. 2015 了解更多细节）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6G5xthKMe9yf6coib4D990uUSYhBaCxahO3PvY2qqMWWrichETic73VHlw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于阅读这篇来自 Courbariaux, David, and Bengio 的 NIPS 2015 论文（探索了我们可以如何 quantize 激活（activation）的方法），这里给出一个简单的备注。一旦你运行完了加权和（weighted sum），然后你执行非线性，你就会得到一个实数。我们需要将其 quantize 到几个比特。如果我们可以做到这一点，我们就能获得巨大的增益，因为我们避免了乘法和加法！这篇论文提到这项研究仍然还在进行中，但结果仍然差强人意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 下一个艰巨挑战：无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6gNgXFfHJeV2x5icU26iasE2qQwt64hicwwsgTzVEibPFo0yUnnt0nJKUlw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，深度学习领域内的大部分成功都是在监督学习领域，而这个领域的学习需要多得惊人的有标签样本。但是，只要机器还是仅依赖表面的统计规律进行学习，它们就无法应对样本分布之外的数据。要实现人类水平的学习，机器就必须要能归纳出关于基本因果关系的更加精准的内在模型。这能让该机器预测未在任何数据中见过的未来情形，而这正是推理、智能和科学的关键组成部分。无监督学习应该会成为深度学习领域内的下一个焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13. 结语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个演讲的关键点也是机器学习基础的关键要素。尤其是通过分布式表征对组合函数（compositional functions）的有效表征，分布式表征已经极大地提升了学习过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一点是硬件友好的机器学习算法的开发。低精度训练这样的机制让我们可以在更大型的数据集上学习更大型的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，深度学习的下一步是无监督学习。这个领域的潜在价值是能让我们真正用上海量的无标签数据、回答关于被观察到的变量的新问题、迁移学习（领域适应，其中机器可以在无需给定模型和领域的情况下学习）和更加结构化的输出（比如翻译）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6yW6t3lFibqjFUMgheTwtuYVZ9Hz976aREKW1Jknveh9hj6hOjg0hPxg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 的这次演讲谈到了很多有趣的主题，我希望这篇概述分享能够引起你的关注，也希望你能从中有所收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016年年度十大Python库</title>
      <link>http://www.iwgc.cn/link/4034092</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自tryolabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;圣诞将至，又到了年终盘点时间，Tryo Labs 和去年一样又推出了一份 2016 年十大 Python 库的榜单。对于这份榜单的筛选条件，Tryo Labs 写道：「我们避开了 Django、Flask 等已经成为今天的标准库的已经成功的项目。另外，这个榜单中有的库是 2016 年之前建立的，但它们在今年的受欢迎度出现了暴增或我们认为它们非常好所以可以进入这个榜单。」下面是榜单详情：&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. Zappa&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://www.zappa.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 AWS Lambda（以及后续的其它项目）发布以来，人们的关注点就全部转移到了无服务器架构上。这些架构让我们可以将微服务（microservice）部署到云端、部署到一个完全可管理的环境中；在这样的环境中，人们不用关心管任何服务器，而只需要分配无状态的、短暂的计算容器（computing container）即可——一个服务提供商即可完全管理。通过这一范式，事件（比如流量尖峰）可以触发更多这些容器的执行，因此有可能能够处理「无限的」水平扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zappa 是一个用于 Python 的无服务器框架，尽管（至少目前）它仅支持 AWS Lambda 和 AWS API Gateway。它使得开发这样架构的应用变得非常简单，能将你从使用 AWS Console 或 API 的繁琐配置工作中解放出来，而且它还有各种用于简化部署和管理不同环境的命令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. Sanic + uvloop&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sanic:&lt;span&gt; https://github.com/channelcat/sanic&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;uvloop: &lt;span&gt;https://magic.io/blog/uvloop-blazing-fast-python-networking/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁说 Python 不能很快？Sanic 不仅有可能是有史以来最好的软件库名字，也可能是有史以来最快的 Python 网页框架，而且似乎也远远超过其它框架。它是一个专为速度而设计的类 Flask 的 Python 3.5+ 网页服务器。另一个库 uvloop 是一个用于 asyncio 的事件循环（event loop，其底层使用了 libuv）的超快速的插件替代。这两个加起来就是一个强大的组合！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Sanic 的作者的基准测试，uvloop 可以驱动 Sanic 每秒处理超过 3.3 万条请求，这实在太强了！（比 node.js 还快）。你的代码可以受益于这种新的 async/await 语法——它们会看起来很整洁；此外我们也喜欢 Flask 风格的 API。你一定要试试 Sanic，而且如果你也在使用 asyncio，你也可以无需太多修改你的代码就能受益于 uvloop。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. asyncpg&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/MagicStack/asyncpg&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟进 asyncio 框架的最新进展，来自 MagicStack 的人为我们带来了这个高效的异步（目前只支持 CPython 3.5）数据库接口库，其是专门为 PostgreSQL 设计的。它有零相关性，这意味不需要安装 libpq。相对而言，withpsycopg2（最流行的 Python 的 PostgreSQL 适配器）需要以文本格式与数据库服务器交换数据；而 asyncpg 则实现了 PostgreSQL 二进制 I/O 协议，这让其不仅支持通用类型，而且还有其它许多性能上的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其基准是很清楚的：asyncpg 平均至少比 psycopg2（或 aiopg）快 3 倍，也比 node.js 和 Go 实现更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. boto3&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/boto/boto3&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你的基础设施部署在 AWS 上或使用了它们的服务（比如 S3），那么你应该非常乐意看到 boto（用于 AWS API 的 Python 接口）被从头到尾完整重写了。而且你不用一次性就完全迁移你的应用：你可以同时使用 boto3 和 boto(2) ；比如仅在你应用中新的部分使用 boto3。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个新的实现在不同的服务间会一致的多，而且因为其使用了数据驱动的方法来在运行时间（runtime）从 JSON 描述文件中生成类，所以其总是可以实现快速更新。再也不用滞后于新的 Amazon API 功能了，赶紧使用 bot3 吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://www.tensorflow.org/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大名鼎鼎的 TensorFlow。自从谷歌在 2015 年 11 月发布以来，这个库已经获得了很多改进，它已成为时下最流行的 GitHub Python 库。简而言之，TensorFlow 是一个使用数据流图（data flow graphs）的数值计算库，可以在 GPU 或 CPU 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去一年里，我们目睹了 TensorFlow 在机器学习社区中掀起了一股新风潮（特别是在深度学习领域），它不仅出现在研究领域，而且在应用领域也非常常见。如果你正在做深度学习并想在高级别接口中使用它，你可以尝试以它为后端的 Keras 或新推出的 TensorFlow-Slim。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.gym+universe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gym：&lt;span&gt;https://gym.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Universe：&lt;span&gt;https://universe.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是人工智能圈内的人，肯定听说过非营利人工智能研究公司 OpenAI。他们的研究人员在今年开源了一些 Python 代码。Gym 是一个用于开发并比较强化学习算法的工具包。它包含一个开源库，这个库收集了一些可被用于测试强化学习算法的测试问题（环境）。它还包含一个站点与 API，能让你对比训练出的算法（代理，agent）的表现。因为它不在乎代理的实现方式，你可以选择使用自己的计算库建立代理：numpy、TensorFlow、Theano 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们最近也发布了 Universe，这是一个用于研究通用人工智能在跨游戏、网页和其他应用上的表现的软件平台。Universe 能完美匹配 gym，因此它能让任何真实世界应用调整进 gym 环境中。研究人员希望这一无限的可能性能够加速对智能代理的研究，从而解决通用任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Bokeh&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;http://bokeh.pydata.org/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能熟知一些提供数据可视化的 Python 库，其中最流行的就是 matplotlib 和 seaborn。然而，Bokeh 被创造用来做交互可视化（interactive visualization），并且面向现代的网页浏览展示。这意味着 Bokeh 能创造出一个可以让你探索来自网页浏览器数据的情节（plot）。比较棒的是它紧密融合了 Juptyer Notebooks，所以你能使用它配合你的专业工具进行研究。它也有一个可选的服务器组件 bokeh-server，其带有许多强大的功能，比如在服务器端对大型数据集进行下采样、流传输数据、变换等。可点击网址 http://bokeh.pydata.org/en/latest/docs/gallery.html 查看案例，看起来很棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.Blaze&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://blaze.readthedocs.io/en/latest/index.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时候，当你对数据集运行分析时，却发现数据集过大，无法一次塞进计算机 RAM 中。如果你无法依赖 numpy 或 Pandas，你通常需要转而使用其他的工具，如 PostgreSQL、MongoDB、Hadoop、Spark 等等。这些工具都有其自身的优缺点，依照任务的特点，总有一种工具是适合你的。但决定转换工具是一项巨大的工程，因为你需要了解这些系统如何工作，以及如何以正确的形式插入数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Blaze 提供了一个统一的接口，让用户无需学习所有数据库技术。Blaze 库的核心是一种计算表达方式。Blaze 本身不会进行任何计算：它只是知道如何指定一个特定的后端，决定谁来执行任务。Blaze 还有其它很多功能（它形成了一个生态系统），它作为一个库被开发出来。例如，Dask 实现了一个可用于 NumPy 数组的插件，可以处理大于内存的内容和利用多核处理器，并且还具有动态任务调度能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.Arrow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/crsmithdev/arrow&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个流行的说法，在计算机科学领域只有两个大问题：无效缓存和命名。我认为这句话忽略了另一个大问题：管理数据时间（managing datetimes）。如果你曾经试图在 Python 中管理数据时间，你就会知道标准库里有巨量的模块和类型：datetime、date、 calendar、 tzinfo、 timedelta、 relativedelta、 pytz 等等。更糟糕的是，时区都自然设定为默认值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Arrow 为开发者提供了「人类的时间（datetime for humans）」，提供了一种清晰的方法来创建、操作、格式化和转换日期、时间和时间戳。它可以用于替换 Python 2 和 3 的 datetime 类型，并提供了一个更友好的界面，同时加入新的功能（如 humanize）弥补了原系统的不足。即使你不需要 Arrow 提供的额外功能，使用它也可以大大减少代码中的引用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. Hug&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;http://www.hug.rest/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公开你的内部 API，这样可以大大简化 Python API 的开发过程。Hug 是一个仅限于 Python3 的库，提供在 Python 中创建 HTTP REST API 的最简单的方式。它不是一个 web 框架（虽然 Hug 提供这样的功能，而且表现很好），它的主要功能是公开正确的标准内部 Python API。这个想法非常简单：一次定义逻辑和结构，并且可以通过多种方式公开你的 API。目前，它支持公开 REST API 或命令行界面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用类型注释（type annotations），让 Hug 不仅为你的 API 生成文件，同时提供验证和明确的错误消息，这可以让你的开发工作（和你的 API 用户的工作）变得轻松很多。Hug 构建在 Falcon 的高性能 HTTP 库之上，这意味着你可以使用任何 wsgi 兼容的服务器（例如 gunicorn）将其部署到生产环境中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://tryolabs.com/blog/2016/12/20/top-10-python-libraries-of-2016/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Nature 2017 年十大展望：继续为量子计算而战</title>
      <link>http://www.iwgc.cn/link/4034094</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、蒋思源、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;希望研究人员们继续为量子计算而战，也敢于面对政治震动带来的后遗症。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6vftMB0pJPlU32EXhnSZ3ppVkAv2L3Mzga8icPhuhEaVG1zncHic0ETibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;海洋对气候的影响&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果美国收回当选总统特朗普做出的气候承诺，中国——这个世界上最大的温室气体排放国将主导减缓气候变迁。2017 年晚些时候，中国将启动排放限额与交易系统以减少温室气体排放。过去三年，全球温室气体排放已趋于稳定，一些科学家希望停滞不前的经济和绿色科技的突起能让 2017 年的温室气体排放有所回落。机器人探测器发回的数据会告诉我们南极洲周围的海洋正在吸收多少二氧化碳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;政治后遗症&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年大选带来的政治震动会在 2017 年显示出其后果。1 月 20 日川普就职后，研究人员就能更清楚地知道这任政府是否会真的搁浅 NASA 气候与地球科学计划（NASA』s climate and Earth-science programmes）或批准用人类胚胎干细胞进行试验。三月，英国开始就脱欧展开正式协商，这也会对科学研究产生巨大影响。4 月初，随着法国、德国相继选举新领导人，科学家将会观察到西方对流行的国家主义的热情是否会继续。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;返回发射方&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国的嫦娥五号将会发回首批月球样本。如果任务成功，科学家将会深入研究这些重达两公斤的岩石和土壤，了解月球的形成与演化。然后，9 月份，NASA 20 岁的 Cassini 探测器将会荣归故里。飞船将飞身经过土星内光环，在大气层分解之前将会发回科学家期待已久的大量相关数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;身体内的世界&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望会有更多关于人类微生物群方面的研究——收集病毒、细菌和其他体内微生物及其基因——看看它们如何影响人类健康。研究人员正在检测微生物群对大脑发育和癌症的影响。另外，分两阶段的美国人类微生物群项目（US Human Micro-biome Project）关注的是人类微生物群与早产、炎症性肠病发病以及 2 型糖尿病的关系，也会在 2017 年发布一些成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia643Iq1RCp7Vefclex1uJ8CCGFG0yEWNGia9WEo24CtCzPayrObYNwticw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基因竞赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2017 年，法院很可能会对加州伯克利大学和位于麻省剑桥的博德研究所（Broad Institute）的 CRISPR-Cas9 专利纠纷作出判决。主张自己发明了基因编辑技术的博德研究所能在专利授权方面收入数十亿美元。NgAgo，一个不分伯仲的基因编辑系统（很难复制）会在后续研究基础上孤注一掷。而且在英国，现在诊所可以申请授权使用一项有争议的辅助生育技术，该技术可以混合三个人的基因，旨在预防儿童患上经由母亲线粒体（细胞产生能量的部分）遗传下来的疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;量子争霸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物理学家们希望 2017 年 将会是量子计算机执行即使是最好的普通类型计算机也无法执行的计算的一年。谷歌，D-wave 和一小撮其他机构正在进行量子争霸。但是不仅仅只有他们在追求更卓越的计算性能高度，微软正在进行一个很有野心另类技术——拓扑量子计算，这种技术把材料中类似粒子的物体运动的信息进行编码，而且他们的这项技术将会比竞争对手的方法更具鲁棒性。在 2017 年晚些时候，微软可能会第一次成功实现这样的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;照亮黑暗&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们将在四月份第一次尝试拍摄一事件视界（event horizon），届时分布在全球的 9 个无线电望远镜一起协作形成一个地球天文台（planet-sized observatory）。事件视界望远镜（Event Horizon Telescope）将会探寻银河系中心的特大质量黑洞。如果四月份的尝试能够成功，所拍摄的图片将可以用于检验广义相对论和获知（照亮）黑洞的活动。与此同时，在 LIGO 和 VIRGO 的研究人员，将会进行第一次高级协同运作，让研究者精确定位特定星系的引力波起源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新型材料&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着今年晚些时候商业化的开始，廉价薄型的太阳能电池即将走出实验室。自 2009 年以来，钙钛矿型太阳能电池的效率急速上升。研究者目前正在努力克服材料上的主要缺点，同时推进生产这种电池的低成本方法。德国汉堡电子同步加速器研究所的一台价值 12 亿欧元欧洲 X 射线自由电子激光器投入使用也使得材料科学领域得到强大支持。该仪器将允许研究人员研究原子细节中的二次化学反应和生物和物理过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Big blue&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界上最大的海洋保护区于今年 12 月正式建立，这让南极洲的罗斯海（Ross Sea）免于商业捕鱼和矿产开发。在南极洲的其他地方，甚至大冰山都能从 Larsen C 冰架上崩解，且自它在 1893 年被发现以来，冰雪的质量已经缩减到了最小。在温暖地区，过去几年对珊瑚白化扩张的研究应该可以解释其为何能在一些区域相对安全的生存下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6fFsklUdbUogibf433NBfn4WvH65Kzo9ia2OiaBEVB5NNdKESUsJwy5yJQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;T 淋巴细胞的反击&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个同类型、复杂的癌症免疫治疗法 CAR-T 看起来好像已经准备投入市场了。药品公司 Kite Pharma 和 Novartis 正在竞争获得批准应用此治疗方法，该疗法涉及的基因工程需要从患者的免疫系统中提取出 T 淋巴细胞，然后使用这些 T 淋巴细胞进行对抗癌症。尽管在一些公司的研究中出现了导致患者死亡的毒性问题，但该疗法今年还是有望获批作为白血病和淋巴瘤患者最后的治疗手段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第九大行星&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;太阳系外的研究可能会帮助确定第九大行星的位置，经过理论计算，它的公转周期大约是 20 万年。直到 2016 年的一项研究发现了一些柯伊伯带（Kuiper-belt）中的星体（这些都是远在冥王星轨道之外的冰冷星体），研究表明了它的存在。NASA 计划在 2017 年 12 月发射一颗人造卫星 Transiting Exoplanet Survey Satellite（TESS），从而展开系外行星搜寻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://www.nature.com/news/2017-sneak-peek-what-the-new-year-holds-for-science-1.21231&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
  </channel>
</rss>
